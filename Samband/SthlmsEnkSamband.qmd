---
title: "Samband mellan variabler"
subtitle: "Tvärsnittsdata från Stockholmsenkäten"
title-block-banner: "#009ca6"
title-block-banner-color: "#FFFFFF"
author: 
  name: Magnus Johansson
  affiliation: RISE Research Institutes of Sweden
  affiliation-url: https://www.ri.se/sv/vad-vi-gor/expertiser/kategoriskt-baserade-matningar
  orcid: 0000-0003-1669-592X
date: last-modified
format: 
  html:
    toc: true
    toc-depth: 5
    toc-title: "Innehållsförteckning"
    embed-resources: true
    standalone: true
    page-layout: full
    logo: rise_logo_quarto.png
    mainfont: 'Lato'
    monofont: 'Roboto Mono'
    code-overflow: wrap
    code-tools: true
    code-fold: true
    number-sections: true
    fig-dpi: 150
    layout-align: left
    linestretch: 1.6
    theme: materia
    link-external-newwindow: true
  pdf:
    papersize: a4
    documentclass: article #article, report or book
    classoption: [twocolumn, portrait]
  revealjs:
    theme: default
    logo: rise_logo_quarto.png
    chalkboard: false
    self-contained: true
    footer: 'Material skapat av magnus.p.johansson@ri.se'
    mainfont: 'Lato'
    slide-level: 4
    scrollable: true
    smaller: false
  docx:
    toc: true
    number-sections: true
    title: "Rasch in Quarto"
    subtitle: "Template file"
    author: "Magnus Johansson"
#    reference-doc: RISEmallMJv6.dotx
execute:
  echo: true
  warning: false
  message: false
  cache: true
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
bibliography: grateful-refs.bib
---

```{r}
library(tidyverse)
library(arrow)
library(lme4)
library(broom)
library(formattable)
library(grateful)
library(GGally)
library(ggiraph)
library(ggdist)
library(pscl)
library(car)
library(parameters)
library(see)
library(performance)
library(modelbased)
library(emmeans)

### set up color palette based on RISE guidelines
RISEprimGreen <- "#009ca6"
RISEprimRed <- "#e83c63"
RISEprimYellow <- "#ffe500"
RISEprimGreenMid <- "#8dc8c7"
RISEprimRedMid <- "#f5a9ab"
RISEprimYellowMid <- "#ffee8d"
RISEprimGreenLight <- "#ebf5f0"
RISEprimRedLight <- "#fde8df"
RISEprimYellowLight <- "#fff7dd"
RISEcompPurple <- "#482d55"
RISEcompGreenDark <- "#0e4e65"

# create a wide palette based on RISE colors
RISEpalette1 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(6)
# "#009CA6" "#5C758B" "#B94F70" "#EC5D4F" "#F5A127" "#FFE500"
RISEpalette2 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(10)

theme_rise <- function(palettesize = 6, fontfamily = "Lato", axissize = 13, titlesize = 15, margins = 12, axisface = "plain") {
  theme(
    text = element_text(family = fontfamily),
    axis.title.x = element_text(
      margin = margin(t = margins),
      size = axissize
    ),
    axis.title.y = element_text(
      margin = margin(r = margins),
      size = axissize
    ),
    plot.title = element_text(
      face = "bold",
      size = titlesize
    ),
    axis.title = element_text(
      face = axisface
    ),
    plot.caption = element_text(
      face = "italic"
    )
  )
}

library(kableExtra)
library(glue)
kbl_rise <- function(data, width = 75, fontsize = 14) {  
  kbl(data, booktabs = T, escape = F, table.attr = glue("style='width:{width}%;'")) %>%
    kable_styling(
      bootstrap_options = c("striped", "hover"),
      position = "left",
      full_width = T,
      font_size = fontsize,
      fixed_thead = T,
      latex_options = c("striped", "scale_down")
    ) %>%
    row_spec(0, bold = T) %>%
    kable_classic(html_font = "Lato")
}


# read data
df <- read_parquet("../DIDapp/data/2023-02-07_ScoredRev.parquet")

årtal <- c(2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020)
sthlm.index.all <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv","Wellbeing")
```

## Deskriptiva data

Vi har tagit fram indexvärden för flera faktorer, och börjar med att titta på hur det ser ut med antal svar per år och index, samt andel missing data. Det krävs svar på minst fem ingående frågor för att ett indexvärde ska beräknas med tillförlitlighet, så de som svarat på färre än fem saknar indexvärde.

Vi tittar först enbart på årskurs 9, eftersom de är yngre.

::: panel-tabset
### Antal svar
```{r}
df2 <- df %>%
  filter(ar > 2004 & ar < 2022) %>%
  filter(ARSKURS == "Åk 9") %>% 
  filter(Kön %in% c("Pojke","Flicka"))

# check number of respondents per year
df2 %>%
  count(ar) %>%
  rename(
    År = ar,
    Antal = n
  ) %>%
  formattable(., table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
```
### Fördelat på kön
```{r}

responsesGender <- df2 %>% 
  rename(År = ar,
         Årskurs = ARSKURS) %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(sthlm.index.all, names_to = "Index", values_to = "Indexvärde") %>% 
  group_by(År,Index,Kön) %>% 
  summarise(Antal = n()) %>% 
  ggplot(aes(x = År, y = Antal, color = Kön)) + 
  geom_line(linewidth = 1) +
  geom_point_interactive(aes(tooltip = Antal),
                         size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Antal respondenter per år",
       subtitle = "Fördelat på kön")

girafe(ggobj = responsesGender)

```

### Antal med missing data
```{r}
missingIndex <- df2 %>% 
  rename(År = ar,
         Årskurs = ARSKURS) %>% 
  select(all_of(sthlm.index.all),År) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  group_by(År,Index) %>%
  count(Indexvärde) %>% 
  filter(is.na(Indexvärde)) %>% 
  # summarise(Svar = count(Index))
  # filter(is.na(Index)) %>% 
  # summarise(`För få svar` = n()) %>% 
  ggplot(aes(x = År, y = n, color = Index, group = Index)) + 
  geom_line(linewidth = 1) +
  geom_point_interactive(aes(tooltip = n),
                         size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Antal saknade svar per år",
       subtitle = "Fördelat på index") +
  ylab("Antal")

girafe(ggobj = missingIndex)
```
### Andel med missing data
```{r}

df2 %>% 
  rename(År = ar) %>% 
  select(all_of(sthlm.index.all),År) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  group_by(År,Index) %>%
  mutate(Svar = case_when(
    is.na(Indexvärde) ~ "För få svar",
    TRUE ~ "Har svar"
  )) %>% 
  count(Svar) %>% 
  mutate(Procent = round(100 * n / sum(n),1)) %>% 
  filter(Svar == "För få svar") %>% 
  ggplot(aes(x = År, y = Procent, color = Index, group = Index)) + 
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Andel saknade svar per år",
       subtitle = "Fördelat på index") +
  ylab("Andel i procent")

```
:::

## Fördelningar av indexvärden

Samtliga år tillsammans.

Höga värden av riskfaktorer = hög risk.

Höga värden av skyddsfaktor "Positiv skolanknytning" (SkolaPositiv) = högt skydd.

Höga värden av Välbefinnande/Wellbeing = högt välbefinnande.

```{r}
df2 %>% 
  rename(År = ar) %>% 
  select(all_of(sthlm.index.all),År) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  ggplot(aes(x = Indexvärde, y = Index, fill = Index)) +
  stat_slab(
    slab_type = "histogram",
    side = "right", show.legend = F,
    scale = 0.85, # defines the height that a slab can reach
    position = position_dodge(width = .7), # distance between elements for dodging
    aes(fill_ramp = after_stat(level), fill = Index),
    .width = c(.50, .75, 1)
  ) +
  #scale_fill_manual(values = RISEpalette2)
  scale_fill_brewer(type = "qual", palette = "Dark2")
```

```{r}
df2 %>% 
  rename(År = ar) %>% 
  select(all_of(sthlm.index.all),År) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  mutate(Index = factor(Index, levels = sthlm.index.all)) %>% 
  ggplot(aes(y = Indexvärde, x = Index, fill = Index)) +
  geom_boxplot(outlier.shape = NA) +
  #scale_fill_manual(values = RISEpalette2)
  scale_fill_brewer(type = "qual", palette = "Dark2")
```


## Stabilitet i sambandsmodeller

Data splittas på årsbasis för att undersöka om sambanden är likartade över tid (2006-2020).

## Korrelationsmatris

Alla variabler utom välbefinnande. Enbart utifrån år 2020.

```{r}
#| fig-width: 9
#| fig-height: 6

sthlm.index <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv")

df2 %>% 
  filter(ar == 2020) %>% 
  select(all_of(sthlm.index),Kön) %>% 
  ggpairs(aes(color = Kön), alpha = 0.8) +
  scale_color_manual(values = RISEpalette1[c(2,5)],
                     aesthetics = c("color", "fill"))
```

### Värden från alla år
```{r}
corrModels <- df2 %>%
  select(all_of(sthlm.index.all),ar) %>% 
  split(.$ar) %>%
  map(~ cor(., use = "pairwise.complete.obs"))
# 
# df2 %>% 
#   select(all_of(sthlm.index.all)) %>% 
#   cor(. , use = "pairwise.complete.obs")

corrTable <- corrModels %>% 
  map(as_tibble) %>% 
  bind_rows() %>% 
  add_column(År = rep(årtal, each = 8)) %>% 
  select(!ar) %>% 
  na.omit()
```


## Utagerande och andra variabler

### Utagerande och Parenting

```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  select(Utagerande, Parenting, Kön) %>% 
  ggplot(aes(x = Parenting, y = Utagerande, color = Kön)) +
  geom_point2(alpha = 0.5, size = 2.2) +
  geom_smooth(linewidth = 1.6) +
  scale_color_manual(values = RISEpalette1[c(1,5)],
                     aesthetics = c("color", "fill"))
```

### LMM Utagerande 1
```{r}
models1 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + Kön, data = .))


# models1 %>%
#   map(summary) %>%
#   map("coefficients") %>%
#   map_df(as_tibble)

compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

compEstimates(models1,3)

sumEstimates <- function(m) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  group_by(term) %>%
  summarise(
    Medel = mean(estimate),
    SD = sd(estimate),
    Max = max(estimate),
    Min = min(estimate),
    MaxDiff = Max - Min
  ) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}

sumEstimates(models1)

compRsq <- function(m) {
  m %>% 
  map(summary) %>% 
  map_dbl("r.squared") %>% 
  as.data.frame() %>%
  rownames_to_column() %>% 
  setNames(c("År","R-squared")) %>% 
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}

compRsq(models1)
```

#### Random intercept kön

```{r}
models1b <- df2 %>% 
  split(.$ar) %>%
  map(~ lmer(Utagerande ~ Parenting + (1|Kön), data = .))
library(broom.mixed)
models1b %>% 
  map(broom.mixed::tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 4), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  kbl_rise()

lmer1 <- df2 %>% 
  filter(ar == 2020) %>%
  lmer(Utagerande ~ Parenting + (1|Kön), data = .)
lm1k <- df2 %>% 
  filter(ar == 2020) %>%
  lm(Utagerande ~ Parenting + Kön, data = .)
AIC(lmer1,lm1k)
```


#### Uppdelat på kön

```{r}

modelsP <- df2 %>%
  filter(Kön == "Pojke") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

modelsF <- df2 %>%
  filter(Kön == "Flicka") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

compEstimatesG <- function(m,n,filename) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write_csv(.,filename) 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}
compEstimatesG(models1,3,"Samband/compEstimates.csv")
compEstimatesG(modelsP,2,"Samband/compEstimatesPojkar.csv")
compEstimatesG(modelsF,2,"Samband/compEstimatesFlickor.csv")

```
#### Tabell
```{r}
allEstimates <- read_csv("Samband/compEstimates.csv") %>% 
  select(!ends_with("KönPojke")) %>% 
  add_column(Respondent = 'Alla')
fEstimates <- read_csv("Samband/compEstimatesFlickor.csv") %>% 
  add_column(Respondent = 'Flickor')
pEstimates <- read_csv("Samband/compEstimatesPojkar.csv") %>% 
  add_column(Respondent = 'Pojkar')

aEstimates <- rbind(allEstimates,fEstimates,pEstimates) %>% 
  janitor::clean_names(case = "snake")

aEstimates %>% 
  group_by(respondent) %>% 
  summarise(medel_intercept = mean(estimate_intercept),
            sd_intercept = sd(estimate_intercept),
            max_intercept = max(estimate_intercept),
            min_intercept = min(estimate_intercept),
            medel_parenting = mean(estimate_parenting),
            sd_parenting = sd(estimate_parenting),
            max_parenting = max(estimate_parenting),
            min_parenting = min(estimate_parenting)
            ) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3))) %>% 
  kbl_rise()

```

#### Tabell standardiserad
```{r}
library(datawizard)
compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

models1 %>% 
  map(datawizard::standardize) %>% 
  map(tidy) %>% 
  bind_rows() %>% 
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 3), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write.csv(.,"Samband/StdEstimates.csv") 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')

#quantile regression

```


#### Plots
```{r}
aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_intercept, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(color = respondent)) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting)) +
  scale_y_continuous(limits = c(-4,4)) +
  scale_x_continuous(limits = c(-4,4)) +

  aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(data = aEstimates %>% filter(respondent == "Alla"),
              aes(intercept = mean(estimate_intercept), slope = mean(estimate_parenting)),
              alpha = 0.86, color = "blue", linetype = 2, linewidth = 2) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
```

#### Plot 2
```{r}

library(ggside)
corSidePlot <- function(data, x, y, smooth = "lm", color) {
  
  data %>%
    ggplot(aes(x = {{ x }}, y = {{ y }}, color = {{ color }})) +
    geom_point2(size = 3, alpha = 0.7) +
    geom_smooth(method = smooth) +
    geom_xsidedensity(aes(y = after_stat(density))) +
    geom_ysidedensity(aes(x = after_stat(density))) +
    geom_xsidehistogram(aes(y = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
    geom_ysidehistogram(aes(x = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
}

df2 %>% 
  corSidePlot(., Utagerande, Parenting)

```

::: panel-tabset
##### 2020
```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2018
```{r}
df2 %>% 
  filter(ar == 2018) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2016
```{r}
df2 %>% 
  filter(ar == 2016) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2014
```{r}
df2 %>% 
  filter(ar == 2014) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
:::

### Kvantil regression
```{r}
library(quantreg)
lq1 <- rq(Utagerande ~ Parenting,
  data = df2, tau = 0.5
)
lm1 <- lm(Utagerande ~ Parenting,
  data = df2
)
AIC(lm1, lq1)
tidy(lm1)
tidy(lq1)

ggplot(df2, aes(Utagerande, Parenting)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", se = T, color = "blue", linewidth = 2) +
  geom_quantile(quantiles = 0.5, color = "red", linewidth = 2) +
  geom_quantile(
    color = "orange", alpha = 0.6,
    quantiles = seq(.1, .9, by = 0.1)
  ) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  )
```


### LMM Utagerande 2
```{r}
models2 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .))

compEstimates(models2,5)
sumEstimates(models2)
compRsq(models2)
```

#### Standardiserade effektstorlekar
```{r}
#df2 %>%
#  split(.$ar) %>%
#  map(~ emmeans(lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)), "Parenting")

m2s <- df2 %>% 
  filter(ar == 2016) %>% 
  lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)

emmeans(m2s, "Parenting")
#eff_size(m2emm, edf = 6041, sigma=sigma(m2s))
# borde gå att skriva en funktion för emmeans som går igenom varje år
```


### Utagerande och kriminalitet

#### Antal brott
```{r}
items.brott <- df %>% 
  select(starts_with("f75")) %>% 
  names()

df2 <- df2 %>% 
  mutate(AntalBrott = rowSums(across(all_of(items.brott)), na.rm = T))

df2 %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_bar(fill = RISEprimGreen)
```

#### Test av olika modeller

##### Vanlig poisson regression
```{r}
brott0 <- glm(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020),
            family = poisson)
summary(brott0)
```

##### Negative binomial
```{r}
library(MASS)
brott.nb <- glm.nb(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott.nb)
```


##### Zero-inflated poisson
```{r}
brott1 <- pscl::zeroinfl(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott1)
```

##### Hurdle negative binomial
```{r}
brott2 <- pscl::hurdle(AntalBrott ~ Utagerande + Kön,
                 dist="negbin", 
                 data = df2 %>% filter(ar == 2020))
summary(brott2)
```

##### AIC jämförelse
```{r}
AIC(brott0,brott.nb,brott1,brott2)
```
Hurdle model har lägst AIC, följd av negative binomial.

#### Visualisering hurdle model
```{r}
predicted <- estimate_expectation(brott2, data = "grid")
plot(predicted) + 
  scale_color_manual(values = RISEpalette1[c(1,5)]) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Hurdle negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
# library(ggeffects)
# pred <- ggpredict(brott2, terms = c("Utagerande","Kön"))
# ggplot(pred, aes(x = x, y = predicted, colour = group)) +
#   geom_line(linewidth = 1.5) +
#   geom_point2() +
#   scale_color_manual(values = RISEpalette1[c(1,5)]) +
#   xlab("Antal självrapporterade brott") +
#   ylab("Indexvärde utagerande")
```

#### Visualisering negative binomial
```{r}
predicted.nb <- estimate_expectation(brott.nb, data = "grid")
plot(predicted.nb) + 
  scale_color_manual(values = RISEpalette1[c(1,5)], aesthetics = c("color","fill")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
```


#### Dikotomiserat utfall
Vi kodar en variabel där antal brott 0-2 = 0, och 3 eller fler blir 1.
```{r}
df2 <- df2 %>% 
  mutate(BrottDik = car::recode(AntalBrott,"0:2=0;3:19=1", as.factor = FALSE))

brott0b <- glm(BrottDik ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020),
            family = binomial)
summary(brott0b)
```

```{r}
plot(parameters(brott0b))

predicted <- estimate_expectation(brott0b, data = "grid")
plot(predicted) +
  scale_color_manual(values = RISEpalette1[c(1,5)], 
                     aesthetics = c("fill","color")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Logistic regression prediction model")

### only for linear models:
# check <- check_normality(brott0)
# plot(check, type = "qq")
```

```{r}
augment(brott0b) %>% 
  filter(BrottDik == 1) %>% 
  select(Utagerande) %>% 
  summary()

augment(brott0b) %>%
  ggplot(aes(x = Utagerande, fill = BrottDik, group = BrottDik)) +
  geom_density(alpha = 0.7) +
  geom_vline(aes(xintercept = 0.9), color = "red", linetype = 2) +
  theme_bw() +
  scale_fill_viridis_c()
  
```

### Machine Learning modeling

#### Logistic penalized regression

```{r}
library(tidymodels)
library(dotwhisker)
library(vip)         # for variable importance plots
library(ranger)
df2$BrottDik2 <- factor(df2$BrottDik, levels = c(0,1),
                        labels = c("Låg","Hög"))

ml_vars <- c("BrottDik2","Utagerande","Kön","Parenting","Community","SkolaNegativ")

df3 <- df2 %>% 
  select(any_of(ml_vars),ar) %>% 
  na.omit()

splits <- initial_split(df3, strata = ar)
df_train <- training(splits)
df_test  <- testing(splits)
val_set <- validation_split(df_train, 
                            strata = ar, 
                            prop = 0.80)
df_fold <- vfold_cv(df_train, v = 10)
```

```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")


lr_fit <- 
  lr_mod %>% 
  fit(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)

lr_recipe <- 
  recipe(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
#| eval: true
#lr_splits <- vfold_cv(df_other, v = 10, strata = ar)
#_res <- tune_grid(lr_mod, ames_rec, resamples = cv_splits, grid = spline_grid)

#lr_reg_grid <- tibble(penalty = 10^seq(-5, -1, length.out = 40))
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)

lr_res <- 
  tune_grid(lr_workflow,
            resamples = df_fold,
            grid = penalty_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# lr_res <-
#   lr_workflow %>%
#   tune_grid(val_set,
#             grid = penalty_grid,
#             control = control_grid(save_pred = TRUE),
#             metrics = metric_set(roc_auc))

lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 
top_models

lr_best <- lr_res %>% 
  select_best()

lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(BrottDik2, `.pred_Hög`) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```


```{r}
#| eval: true

last_lr_mod <- 
  logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")

last_lr_workflow <- 
  lr_workflow %>% 
  update_model(last_lr_mod)

last_lr_fit <- 
  last_lr_workflow %>% 
  last_fit(splits)

last_lr_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```


## Programvara som använts

```{r}
#| label: packagesv
pkgs <- cite_packages(
  cite.tidyverse = TRUE,
  output = "table",
  bib.file = "grateful-refs.bib",
  include.RStudio = TRUE
)
formattable(pkgs,
  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
)
```

## Referenser
