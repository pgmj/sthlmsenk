---
title: "Samband mellan variabler"
subtitle: "Tvärsnittsdata från Stockholmsenkäten"
title-block-banner: "#009ca6"
title-block-banner-color: "#FFFFFF"
author: 
  name: Magnus Johansson
  affiliation: RISE Research Institutes of Sweden
  affiliation-url: https://www.ri.se/sv/vad-vi-gor/expertiser/kategoriskt-baserade-matningar
  orcid: 0000-0003-1669-592X
date: last-modified
format: 
  html:
    toc: true
    toc-depth: 5
    toc-title: "Innehållsförteckning"
    embed-resources: true
    standalone: true
    page-layout: full
    mainfont: 'Lato'
    monofont: 'Roboto Mono'
    code-overflow: wrap
    code-tools: true
    code-fold: true
    number-sections: true
    fig-dpi: 150
    layout-align: left
    linestretch: 1.6
    theme: materia
    link-external-newwindow: true
execute:
  echo: true
  warning: false
  message: false
  cache: true
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
bibliography: grateful-refs.bib
---

```{r}
library(tidyverse)
library(arrow)
library(lme4)
library(broom)
library(formattable)
library(grateful)
library(GGally)
#library(ggiraph)
library(ggdist)
library(pscl)
library(car)
library(easystats)
#library(emmeans)
library(marginaleffects)
library(modelsummary)
library(kableExtra)
library(glue)
library(lavaan)
library(lavaanPlot)
library(quantreg)
library(readxl)
library(MASS)
library(patchwork)


### some commands exist in multiple packages, here we define preferred ones that are frequently used
select <- dplyr::select
count <- dplyr::count
recode <- car::recode
rename <- dplyr::rename

### set up color palette based on RISE guidelines
RISEprimGreen <- "#009ca6"
RISEprimRed <- "#e83c63"
RISEprimYellow <- "#ffe500"
RISEprimGreenMid <- "#8dc8c7"
RISEprimRedMid <- "#f5a9ab"
RISEprimYellowMid <- "#ffee8d"
RISEprimGreenLight <- "#ebf5f0"
RISEprimRedLight <- "#fde8df"
RISEprimYellowLight <- "#fff7dd"
RISEcompPurple <- "#482d55"
RISEcompGreenDark <- "#0e4e65"

# create a wide palette based on RISE colors
RISEpalette1 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(6)
# "#009CA6" "#5C758B" "#B94F70" "#EC5D4F" "#F5A127" "#FFE500"
RISEpalette2 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(10)

theme_rise <- function(fontfamily = "Lato", axissize = 13, titlesize = 15, margins = 12, axisface = "plain", panelDist = 0.6, ...) {
  theme_minimal() + 
    theme(text = element_text(family = fontfamily), 
          axis.title.x = element_text(margin = margin(t = margins), size = axissize), 
          axis.title.y = element_text(margin = margin(r = margins), size = axissize), 
          plot.title = element_text(face = "bold", size = titlesize), 
          axis.title = element_text(face = axisface), 
          plot.caption = element_text(face = "italic"), 
          legend.text = element_text(family = fontfamily), 
          legend.background = element_rect(color = "lightgrey"), 
          strip.background = element_rect(color = "lightgrey"), 
          panel.spacing = unit(panelDist, "cm", data = NULL), 
          panel.border = element_rect(color = "grey", fill = NA), ...)
}
# set theme default for the session/document
theme_set(theme_rise())

### RISE color palettes 
# the two palettes below have been checked for color blindness compatibility using library(colorblindcheck) 
RISEpalette8 <- c("#009CA6", "#428092", "#84657F", "#C6496C", "#EB5454", "#F18438", "#F8B41C", "#FFE500") 
RISEpalette6 <- c("#009CA6", "#5C758B", "#B94F70", "#EC5D4F", "#F5A127", "#FFE500") 

### palettes can be created using the three RISE primary colors and changing the number at the end: 
# RISEpalette1 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(6) 

# gender split colors, replace label based on your dataset
gender_colors <- c("Pojke" = "#F5A127", "Flicka" = "#009CA6")
# these can be used in ggplots as `+ scale_color_gender()` or `+ scale_fill_gender()`
scale_color_gender <- partial(scale_color_manual, values = gender_colors)
scale_fill_gender <- partial(scale_fill_manual, values = gender_colors)

DIDcolorsGGYR <- c("lightgrey","#509B8E", "#E2C578", "#DB7358")
DIDcolorsRYGG <- c("#DB7358", "#E2C578", "#509B8E", "lightgrey")

kbl_rise <- function(data, tbl_width = 65, fontsize = 14, fontfamily = "Arial",
                     options = c("striped", "hover"), ...) {
  kbl(data, booktabs = T, escape = F,
      table.attr = glue("data-quarto-disable-processing='true' style='width:{tbl_width}%;'")) %>%
    kable_styling(
      bootstrap_options = options,
      position = "left",
      full_width = T,
      font_size = fontsize,
      fixed_thead = T,
      latex_options = c("striped", "scale_down"),
      ...
    ) %>%
    row_spec(0, bold = T) %>%
    kable_classic(html_font = fontfamily)
}


# read data
df.all <- read_parquet("../data/2023-10-27_ScoredRev.parquet")

årtal <- c(2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020,2022)
sthlm.index.all <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv","Wellbeing")

sthlm.index <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv")

df <- df.all %>%
  filter(ar > 2004 & ar < 2024) %>%
  filter(ARSKURS == "Åk 9") %>% 
  filter(Kön %in% c("Pojke","Flicka")) %>% 
  rename(År = ar,
         Årskurs = ARSKURS,
         Kommun = DIDkommun)



## riskgruppsindelningar

# läs in gränsvärden
rslimits <- read_csv("../DIDapp/data/2023-05-07_rslimitsNoRev.csv")
rslimits.prot <- read_csv("../DIDapp/data/2023-05-07_protective.csv")

# skapa nya variabler för respektive indexvärde
df <- df %>% 
  mutate(riskUtagerande = case_when(Utagerande < rslimits$Utagerande[1] ~ "Låg risk",
                                    Utagerande > rslimits$Utagerande[2] ~ "Förhöjd risk",
                                    Utagerande <= rslimits$Utagerande[2] & Utagerande >= rslimits$Utagerande[1] ~ "Något förhöjd risk")) %>% 
  mutate(riskSkolaNegativ = case_when(SkolaNegativ < rslimits$SkolaNegativ[1] ~ "Låg risk",
                                      SkolaNegativ > rslimits$SkolaNegativ[2] ~ "Förhöjd risk",
                                      SkolaNegativ <= rslimits$SkolaNegativ[2] & SkolaNegativ >= rslimits$SkolaNegativ[1] ~ "Något förhöjd risk")) %>%
  mutate(riskParenting = case_when(Parenting < rslimits$Parenting[1] ~ "Låg risk",
                                   Parenting > rslimits$Parenting[2] ~ "Förhöjd risk",
                                   Parenting <= rslimits$Parenting[2] & Parenting >= rslimits$Parenting[1] ~ "Något förhöjd risk")) %>%
  mutate(riskCommunity = case_when(Community < rslimits$Community[1] ~ "Låg risk",
                                   Community > rslimits$Community[2] ~ "Förhöjd risk",
                                   Community <= rslimits$Community[2] & Community >= rslimits$Community[1] ~ "Något förhöjd risk")) %>%
  mutate(riskPsykSomBesv = case_when(PsykSomBesv < rslimits$PsykSomBesv[1] ~ "Låg risk",
                                     PsykSomBesv > rslimits$PsykSomBesv[2] ~ "Förhöjd risk",
                                     PsykSomBesv <= rslimits$PsykSomBesv[2] & PsykSomBesv >= rslimits$PsykSomBesv[1] ~ "Något förhöjd risk")) %>%
  mutate(skyddSkolaPositiv = case_when(SkolaPositiv < rslimits.prot$SkolaPositiv[2] ~ "<85",
                                      SkolaPositiv > rslimits.prot$SkolaPositiv[2] ~ "Förhöjt skydd")) %>% 
  mutate(across(starts_with("risk"), ~ factor(.x, levels = c("Låg risk", "Något förhöjd risk", "Förhöjd risk"))))



df.f <- df %>% 
  filter(Kön == "Flicka")

df.p <- df %>%
  filter(Kön == "Pojke")
```

## Deskriptiva data

Vi har tagit fram indexvärden för flera faktorer, och börjar med att titta på hur det ser ut med antal svar per år och index, samt andel missing data. Det krävs svar på minst fem ingående frågor för att ett indexvärde ska beräknas med tillförlitlighet, så de som svarat på färre än fem saknar indexvärde.

Vi tittar först enbart på årskurs 9 eftersom de är intressanta som yngre målgrupp ur ett preventionsperspektiv. Vi inkluderar enbart individer som svarat antingen pojke eller flicka på frågan om könstillhörighet. 

Analyserna görs separat för pojkar och flickor. Enbart individer med kompletta svar på variabler som ingår i respektive analys tas med i analyserna i detta skede.

::: panel-tabset
### Antal svar per år och kommun
```{r}
# check number of respondents per year
df %>%
  count(År) %>%
  rename(
    Antal = n
  ) %>%
  kbl_rise()

# per municipality
df %>%
  count(Kommun) %>%
  rename(
    Antal = n
  ) %>%
  arrange(desc(Antal)) %>% 
  kbl_rise()
  
```
### Fördelat på kön
```{r}
df %>%
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(sthlm.index.all, names_to = "Index", values_to = "Indexvärde") %>% 
  group_by(År,Index,Kön) %>% 
  summarise(Antal = n()) %>% 
  ggplot(aes(x = År, y = Antal, color = Kön)) + 
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Antal respondenter per år",
       subtitle = "Fördelat på kön")
```
### Andel med missing data
```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  group_by(År,Index,Kön) %>%
  mutate(Svar = case_when(
    is.na(Indexvärde) ~ "För få svar",
    TRUE ~ "Har svar"
  )) %>% 
  count(Svar) %>% 
  mutate(Procent = round(100 * n / sum(n),1)) %>% 
  filter(Svar == "För få svar") %>% 
  ggplot(aes(x = År, y = Procent, color = Index, group = Index)) + 
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Andel saknade svar per år",
       subtitle = "Fördelat på index") +
  ylab("Andel i procent") +
  facet_wrap(~Kön)

```
:::

### Fördelningar av indexvärden

Samtliga år tillsammans.

Höga värden av riskfaktorer = hög risk.

Höga värden av skyddsfaktor "Positiv skolanknytning" (SkolaPositiv) = högt skydd.

Höga värden av Välbefinnande/Wellbeing = högt välbefinnande.

```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  ggplot(aes(x = Indexvärde, fill = Kön)) +
  geom_histogram(alpha = 0.8) +
  scale_fill_gender() +
  facet_wrap(~Index) +
  labs(title = "Fördelning av indexvärden",
       subtitle = "2006-2022, pojkar och flickor, enbart åk 9",
       x = "Indexvärde",
       y = "Antal")
```

```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(sthlm.index.all, 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  mutate(Index = factor(Index, levels = sthlm.index.all)) %>% 
  ggplot(aes(y = Indexvärde, x = Index, fill = Kön)) +
  geom_boxplot(outlier.shape = NA) +
  scale_fill_gender() +
  labs(title = "Fördelning av indexvärden",
       subtitle = "2006-2022, pojkar och flickor, enbart åk 9",
       x = "Index",
       y = "Indexvärde")
```

### Fördelning av riskgrupp

```{r}
df %>% 
  select(starts_with("risk")) %>% 
  pivot_longer(everything()) %>%
  separate_wider_delim(name, names = c(NA,"Riskgrupp"), delim = "isk") %>% 
  count(Riskgrupp,value) %>%
  mutate(value = factor(value, levels = c("Låg risk","Något förhöjd risk","Förhöjd risk"),
                            labels = c("Låg risk","Något förhöjd risk","Förhöjd risk")
                        )) %>% 
  mutate(value = forcats::fct_rev(value)) %>% 
  
  ggplot(aes(x = Riskgrupp, y = n, fill = value)) +
  geom_col() +
  geom_text(aes(label = n),
            position = position_stack(vjust = .5)) +
  scale_fill_manual('Riskgrupp', values = DIDcolorsRYGG) +
  labs(title = "Fördelning av riskgrupp",
       subtitle = "2006-2022, pojkar och flickor, enbart åk 9",
       x = "Riskfaktor",
       y = "Antal") +
  update_geom_defaults("text", list(family = "Lato"))
  
```


## Psykiska/psykosomatiska besvär

Vi utgår från att bristande föräldraskap, vantrivsel i skolan, och närsamhället är riskfaktorer.

### Flickor

Först visualisering av data utifrån kontinuerliga variabler

```{r}
df.f %>% 
  ggplot(aes(x = Parenting, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 

df.f %>% 
  ggplot(aes(x = SkolaNegativ, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 

df.f %>% 
  ggplot(aes(x = Community, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 
```

Sedan visualisering med riskgruppsindelning

```{r}
#| echo: false

# df.f %>% 
#   drop_na(riskParenting) %>% 
#   ggplot(aes(x = riskParenting, y = PsykSomBesv, color = riskParenting, fill = riskParenting)) +
#   geom_jitter(alpha = 0.1, width = 0.2) +
#   geom_boxplot(alpha = 0.7, width = 0.5, notch = T) +
#   scale_color_manual('Riskgrupp', values = DIDcolorsGGYR[2:4], aesthetics = c("color","fill")) +
#   labs(title = "Bristande föräldraskap",
#        subtitle = "2006-2022, flickor, enbart åk 9",
#        x = "Riskgrupp",
#        y = "Psykiska/psykosomatiska besvär")
```

```{r}
riskVSoutcome <- function(data,riskfactor,outcome,title) {
  data %>% 
    drop_na(riskfactor) %>% 
    ggplot(aes(x = !!sym(riskfactor), y = !!sym(outcome), color = !!sym(riskfactor), fill = !!sym(riskfactor))) +
    geom_jitter(alpha = 0.1, width = 0.2) +
    geom_boxplot(alpha = 0.7, width = 0.5, notch = T) +
    scale_color_manual('Riskgrupp', values = DIDcolorsGGYR[2:4], aesthetics = c("color","fill")) +
    labs(title = paste0(title),
         subtitle = "2006-2022, flickor åk 9",
         x = "Riskgrupp",
         y = "Psykiska/psykosomatiska besvär")
}

riskVSoutcome(df.f,"riskParenting","PsykSomBesv","Bristande föräldraskap")
riskVSoutcome(df.f,"riskSkolaNegativ","PsykSomBesv","Vantrivsel i skolan")
riskVSoutcome(df.f,"riskCommunity","PsykSomBesv","Närsamhälle risk")
```

#### Statistisk modellering

##### Med kontinuerliga variabler

```{r}
psy1_f <- 
  df.f %>% 
  lm(PsykSomBesv ~ Parenting + SkolaNegativ + Community, 
     data = .)
check_model(psy1_f)
```

VIF is low, which is good. Residuals are non-normal, which is not good. We can use a robust estimator (HC3 as implemented in [marginaleffects](https://marginaleffects.com/vignettes/uncertainty.html#robust-standard-errors)) to get better standard errors.

```{r}
avg_slopes(psy1_f, vcov = "HC3")
plot_predictions(psy1_f, condition = "Parenting", vcov = "HC3") +
  coord_cartesian(ylim = c(-2,2))
```

#### Quantile regression

```{r}

```


#### Random forest regression


#### SEM

First CFA to review the measurement model fit.

```{r}
allItemInfo <- read_csv("../data/2024-01-23_allItemParams.csv")
items.psyk <- allItemInfo %>% 
  filter(Index == "PsykSomBesv") %>% 
  pull(itemnr)
items.parent <- allItemInfo %>% 
  filter(Index == "Parenting") %>% 
  pull(itemnr)
items.skolaneg <- allItemInfo %>% 
  filter(Index == "SkolaNegativ") %>% 
  pull(itemnr)

utfall_psy <- "PsykSomBesvCFA =~ F88 + F89 + F91 + F92 + F93 + F95 + F97 + F98 + F99
             ParentingCFA =~ F80 + f83b + f83d + f83e + f83f + F58
             SkolaNegativCFA =~ f54e +f54f+ f54i+ f54k + f54m +f54o +f54q
              "

mm1 <- cfa(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

# create table with model fit metrics
# define fit metrics of interest
fit_metrics_robust <- c("chisq.scaled", "df", "pvalue.scaled", 
                         "cfi.scaled", "tli.scaled", "rmsea.scaled", "srmr")
fitmeasures(mm1, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
```

```{r}
lavaanPlot(model = mm1, 
           coefs = T, stand = T, covs = T,
           node_options = list(fontname = "Helvetica"), 
           edge_options = list(color = "grey"),
           graph_options = list(rankdir = "LR"))
```

SEM

```{r}
utfall_psy <- "PsykSomBesvCFA =~ F88 + F89 + F91 + F92 + F93 + F95 + F97 + F98 + F99
             ParentingCFA =~ F80 + f83b + f83d + f83e + f83f + F58
             SkolaNegativCFA =~ f54e +f54f+ f54i+ f54k + f54m +f54o +f54q
             PsykSomBesvCFA ~ a*ParentingCFA + b*SkolaNegativCFA
              "

psy_sem1 <- sem(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

fitmeasures(psy_sem1, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')

lavResiduals(psy_sem1)

lavaanPlot(model = psy_sem1,
           coefs = T, stand = T, covs = T,
           node_options = list(fontname = "Helvetica"), 
           edge_options = list(color = "grey"),
           graph_options = list(rankdir = "LR"))

library(semPlot)
semPaths(object = psy_sem1,
         whatLabels="est")

psy_sem1_out <- summary(psy_sem1, standardized = TRUE)

psy_sem1_out$pe %>% 
  filter(op == "~") %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  kbl_rise()
```

check residuals for SEM

```{r}
# https://github.com/yrosseel/lavaan/issues/269
lavResidualsY <- function(object,
                          ynames = lavNames(object, "ov.nox"),
                          xnames = lavNames(object, "ov.x")){
  pred <- lavPredictY(object,
                      ynames = ynames,
                      xnames = xnames) |> 
    as.data.frame()
  
  d <- inspect(object, "data") |> 
    as.data.frame()

  r <- lapply(names(pred), function(x){
    pred[[x]] - d[[x]]
  })

  res <- do.call(cbind, r) |> 
    as.data.frame()
  names(res) <- names(pred)
  
  res
}

lavResidualsY(psy_sem1,
              ynames = c("F88","F89","F91","F92","F93","F95","F97","F98","F99"),
              xnames = c("F80","f83b","f83d","f83e","f83f","F58"))

# "f54e","f54f","f54i","f54k","f54m","f54o","f54q"

```

no support for DWLS estimator output in lavPredictY. Let's pretend our variables are continuous.

```{r}
psy_sem1c <- sem(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "ML",
)

summary(psy_sem1c, fit.measures = TRUE, standardized = TRUE)

psy_sem1c_resids <- lavResidualsY(psy_sem1c,
              ynames = c("F88","F89","F91","F92","F93","F95","F97","F98","F99"),
              xnames = c("F80","f83b","f83d","f83e","f83f","F58"))

glimpse(psy_sem1c_resids)

mvnormtest::mshapiro.test(t(sample(psy_sem1c_resids, 100, replace = TRUE)))

```

SEM with fixed factor loadings @1

```{r}
utfall_psy2 <- "PsykSomBesvCFA =~ 1*F88 + 1*F89 + 1*F91 + 1*F92 + 1*F93 + 1*F95 + 1*F97 + 1*F98 + 1*F99
             ParentingCFA =~ 1*F80 + 1*f83b + 1*f83d + 1*f83e + 1*f83f + 1*F58
             SkolaNegativCFA =~ 1*f54e + 1*f54f + 1*f54i + 1*f54k + 1*f54m + 1*f54o + 1*f54q
             PsykSomBesvCFA ~ a*ParentingCFA + b*SkolaNegativCFA
              "

psy_sem2 <- sem(
  model = utfall_psy2,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

fitmeasures(psy_sem2, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
```


##### Riskgrupp

```{r}
psy2_f <- 
  df.f %>% 
  lm(PsykSomBesv ~ riskParenting + riskSkolaNegativ + riskCommunity, 
     data = .)
#check_model(psy2_f)
check_normality(psy2_f)
avg_slopes(psy2_f)
```

```{r}
plot_predictions(psy2_f, "riskParenting") +
  coord_cartesian(ylim = c(-2, 2))
plot_predictions(psy2_f, "riskSkolaNegativ") +
  coord_cartesian(ylim = c(-2, 2))
plot_predictions(psy2_f, "riskCommunity") +
  coord_cartesian(ylim = c(-2, 2))
```


## Kriminalitet

Det finns 19 frågor som handlar om självrapportering av att ha begått olika typer av brott.

#### Antal brott
```{r}
items.brott <- df %>% 
  select(starts_with("f75")) %>% 
  names()

itemlabels_brott <- read_excel("10_Brott/BrottItemlabels.xls")

itemlabels_brott %>% 
  filter(itemnr %in% items.brott) %>%
  kbl_rise() 
```

Summerar vi dem per respondent ser distributionen av individer som rapporterar att ha begått ett visst antal brott vid ett och samma mättillfälle enligt nedan.

```{r}
df <- df %>% 
  mutate(AntalBrott = rowSums(across(all_of(items.brott)), na.rm = T))

df %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_bar(fill = RISEprimGreen)

df %>% 
  ggplot(aes(x = AntalBrott, fill = Kön)) +
  geom_bar(alpha = 0.8, position = "fill") +
  scale_fill_manual(values = c(RISEprimGreen, "orange")) +
  labs(title = "Antal brott fördelat på kön",
       x = "Antal brott",
       y = "Andel")
```

Flickor begår något oftare 1-2 brott än pojkar, men sedan vänder trenden.

Vilken typ av brott är vanligare bland pojkar respektive flickor?

```{r}
brott.kön <- 
  df %>% 
  select(Kön, all_of(items.brott)) %>% 
  glm(Kön ~ ., data = ., family = binomial(link = "logit"))

#modelsummary(brott.kön, exponentiate = TRUE)

tidy(brott.kön) %>% 
  filter(!p.value > 0.05) %>% 
  arrange(desc(estimate)) %>% 
  left_join(itemlabels_brott, by = c("term" = "itemnr")) %>% 
  mutate_if(is.numeric, round, 2) %>%
  kbl_rise()
```

Brott ovanför Intercept-raden är vanligare bland pojkar. Desto längre från Intercept, desto större skillnad mellan pojkars och flickors sannolikhet att begå brott av den typen. Brott som ej har en statistiskt signifikant skillnad är inte med i tabellen. Men p.g.a. vårt stora sampel är statistisk signifikans inte nödvändigtvis en indikator på att det är stor skillnad, här gäller det snarare att titta på "estimate" i tabellen.

```{r}
brottlabels <- itemlabels_brott$item[c(1:19)] %>% 
  rev()

parameters(brott.kön, ci_method="wald") %>% 
  plot() +
  scale_color_manual(values = c("orange", RISEprimGreen)) +
  labs(title = str_wrap("Skillnad mellan pojkar och flickor i sannolikhet att självrapportera olika typer av brott"),
       subtitle = str_wrap("Blågröna prickar indikerar brott med högre sannolikhet att begås av flickor, om linjen för konfidensintervallet inte korsar noll-strecket. Längre avstånd från 0 = större skillnad mellan könen."),
       #x = "",
       y = "Brottstyp") +
  theme_rise() +
  guides(color = "none") +
  scale_y_discrete(labels = str_wrap(paste0(brottlabels), width = 36))
```


Vi kan också titta på hur stor andel av respondenterna som rapporterar att ha begått ett visst antal brott vid ett och samma mättillfälle.

```{r}
df %>% 
  count(AntalBrott) %>%
  mutate(Andel = 100*n/sum(n)) %>%
  ggplot(aes(y = Andel, x = AntalBrott)) +
  geom_col(fill = RISEprimGreen) +
  geom_text(aes(label = paste0(round(Andel, 1), "%")), 
            vjust = -0.5, size = 3) 

df %>% 
  count(AntalBrott) %>%
  mutate(Andel = 100*n/sum(n)) %>%
  slice(1:4) %>% 
  summarise(Andel = sum(Andel) %>% round(1)) %>% 
  kbl_rise()
```

82.3 % av respondenterna rapporterar max 3 brott, varav 36.5 % rapporterar 0 brott.

Vilka brott som självrapporteras oftast?

```{r}
df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  arrange(desc(n)) %>% 
  mutate(Andel = 100*n/sum(n)) %>%
  ggplot(aes(y = Andel, x = reorder(item, n))) +
  geom_col(fill = RISEprimGreen) +
  geom_text(aes(label = paste0(round(Andel, 1), "%")), 
            hjust = -0.3, size = 4) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8)) +
  labs(x = "Brott", y = "Andel (%)") 

df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  arrange(desc(n)) %>% 
  slice(1:5) %>% 
  left_join(itemlabels_brott, by = c("item" = "itemnr")) %>%
  select(!n) %>% 
  kbl_rise()

df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  mutate(Andel = 100*n/sum(n)) %>%
  arrange(desc(n)) %>% 
  slice(1:3) %>% 
  summarise(Summa = sum(Andel))
```

De tre vanligaste brotten står för 49% av alla brott som självrapporteras. 

Vilka brott rapporteras när man rapporterar fler än 0?

```{r}
df %>% 
  filter(AntalBrott > 0) %>% 
  select(all_of(items.brott),AntalBrott) %>% 
  pivot_longer(all_of(items.brott), names_to = "item", values_to = "svar") %>% 

  ggplot(aes(y = svar, x = AntalBrott, fill = item)) +
  geom_col() +
  scale_fill_viridis_d()
  
```

### Statistisk modell för pojkar

Vi tittar först på Antal Brott som utfall. Distributionen av data följer en negativ exponentiell kurva, vilket är vanligt för räknevariabler. Vi använder därför en negativ binomial regressionsmodell. Det är också möjligt att en s.k. hurdle-modell fungerar väl med denna typ av data.

#### Negative binomial regression

```{r}
brott.nb <- glm.nb(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Pojke"))
modelsummary(brott.nb)

p1 <- plot_predictions(brott.nb, cond = "Utagerande", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p2 <- plot_predictions(brott.nb, cond = "Parenting", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p3 <- plot_predictions(brott.nb, cond = "SkolaNegativ", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p4 <- plot_predictions(brott.nb, cond = "Community", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p1 + p2 + p3 + p4 
```

Var passeras antal brott = 3 på de två prediktorerna som visar starkast samband, enligt modellen? OBS att det enbart är pojkar i modellen.

```{r}
predictions(brott.nb, newdata = datagrid(Utagerande = seq(0.5,1.2, 0.05)), vcov = "HC3")
predictions(brott.nb, newdata = datagrid(Parenting = seq(1,1.5, 0.05)), vcov = "HC3")
```

Enligt modellen är det vid Utagerande 0.75 (även nedre konfidensintervallet går över 3) och Parenting = 1.3 (eller 1.5 där nedre konfidensintervall överstiger 3) som AntalBrott överstiger 3.

```{r}
rslimits %>% 
  select(Utagerande, Parenting) %>%
  kbl_rise()

```

Sett till brott som utfall ser vi alltså vissa skillnader mot de distributionsbaserade gränsvärden som hittills använts, om vi tänker att det är rimligt att se 3 brott som en gräns. 


#### Hurdle negative binomial
```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
modelsummary(brott.hrd)
```

```{r}
p1 <- plot_predictions(brott.hrd, cond = "Utagerande") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p2 <- plot_predictions(brott.hrd, cond = "Parenting") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p3 <- plot_predictions(brott.hrd, cond = "SkolaNegativ") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p4 <- plot_predictions(brott.hrd, cond = "Community") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p1 + p2 + p3 + p4 +
  plot_annotation(title = "Riskfaktorer för självrapporterat antal begångna brott - Pojkar",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(0.6,1, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(1,1.5, 0.02)))

predictions(brott.hrd, newdata = datagrid(Utagerande = seq(0.5,1.5, 0.01))) %>% 
  ggplot(aes(x = Utagerande, y = estimate)) +
  geom_line() +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(x = "Utagerande", y = "Antal brott")

```

Hurdle-modellen ger liknande resultat, Utagerande = 0.7 (CI lower = 0.74) och Parenting ca 1.2 (CI lower = 1.34). 

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(1.1, 1.36, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(2.3,2.7, 0.02)))
```

För antal brott = 4 blir 

- Utagerande = 1.26 (CI lower 1.32)
- Parenting = 2.38 (CI lower 2.66)
```{r}
AIC(brott.nb,brott.hrd)
```

Hurdle-modellen verkar passa data något bättre. Vi såg i modelsummary-outputen tidigare även att RMSE var något lägre för Hurdle-modellen. 


### Statistisk modell för flickor

#### Hurdle negative binomial

```{r}
df %>% 
  filter(Kön == "Flicka") %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_histogram(binwidth = 1)
```


```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Flicka"),
            dist = "negbin")
modelsummary(brott.hrd)

```

```{r}
p1 <- plot_predictions(brott.hrd, cond = "Utagerande") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p2 <- plot_predictions(brott.hrd, cond = "Parenting") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p3 <- plot_predictions(brott.hrd, cond = "SkolaNegativ") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p4 <- plot_predictions(brott.hrd, cond = "Community") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p1 + p2 + p3 + p4 +
  plot_annotation(title = "Riskfaktorer för självrapporterat antal begångna brott - Flickor",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(1,1.5, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(2,4, 0.1)))
```

Gränsvärden för flickor:

- Utagerande = 1.12 och CI lower 1.16
- Parenting = når ej upp till antal brott = 3 någonstans längs riskfaktorns skala.

### Skolresultat som riskfaktor

```{r}
df <- df %>% 
  mutate(across(starts_with("F65"), ~ car::recode(.x,"'Streck' = 0;
                                                  'F' = 1;
                                                  'E' = 2;
                                                  'D' = 3;
                                                  'C' = 4;
                                                  'B' = 5;
                                                  'A' = 6;
                                                  ",as.factor=FALSE),
         .names = "{col}_num")) %>%
  df <- df %>% mutate(Skola3betygMedel = rowMeans(.[,c("F65a_num","F65b_num","F65c_num")], na.rm = FALSE))

hist(df$Skola3betygMedel, breaks = 25)
```

```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community + Skola3betygMedel, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
plot_predictions(brott.hrd, cond = "Skola3betygMedel") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(title = "Riskfaktorer för självrapporterat antal begångna brott - Pojkar",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community + Skola3betygMedel, 
            data = df %>% filter(Kön == "Flicka"),
            dist = "negbin")
plot_predictions(brott.hrd, cond = "Skola3betygMedel") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(title = "Riskfaktorer för självrapporterat antal begångna brott - Flickor",
       subtitle = "Hurdle negative binomial regression model")
```


## Substansbruk






## Stabilitet i sambandsmodeller

Data splittas på årsbasis för att undersöka om sambanden är likartade över tid (2006-2020).

## Korrelationsmatris

Alla variabler utom välbefinnande. Enbart utifrån år 2020.

```{r}
#| fig-width: 9
#| fig-height: 6

df %>% 
  filter(ar == 2020) %>% 
  select(all_of(sthlm.index),Kön) %>% 
  ggpairs(aes(color = Kön), alpha = 0.8) +
  scale_color_manual(values = RISEpalette1[c(2,5)],
                     aesthetics = c("color", "fill"))
```

### Värden från alla år
```{r}
corrModels <- df2 %>%
  select(all_of(sthlm.index.all),ar) %>% 
  split(.$ar) %>%
  map(~ cor(., use = "pairwise.complete.obs"))
# 
# df2 %>% 
#   select(all_of(sthlm.index.all)) %>% 
#   cor(. , use = "pairwise.complete.obs")

corrTable <- corrModels %>% 
  map(as_tibble) %>% 
  bind_rows() %>% 
  add_column(År = rep(årtal, each = 8)) %>% 
  select(!ar) %>% 
  na.omit()
```


## Utagerande och andra variabler

### Utagerande och Parenting

```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  select(Utagerande, Parenting, Kön) %>% 
  ggplot(aes(x = Parenting, y = Utagerande, color = Kön)) +
  geom_point2(alpha = 0.5, size = 2.2) +
  geom_smooth(linewidth = 1.6) +
  scale_color_manual(values = RISEpalette1[c(1,5)],
                     aesthetics = c("color", "fill"))
```

### LMM Utagerande 1
```{r}
models1 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + Kön, data = .))


# models1 %>%
#   map(summary) %>%
#   map("coefficients") %>%
#   map_df(as_tibble)

compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

compEstimates(models1,3)

sumEstimates <- function(m) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  group_by(term) %>%
  summarise(
    Medel = mean(estimate),
    SD = sd(estimate),
    Max = max(estimate),
    Min = min(estimate),
    MaxDiff = Max - Min
  ) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}

sumEstimates(models1)

# compare r-squared across years
compRsq <- function(m) {
  m %>% 
  map(summary) %>% 
  map_dbl("r.squared") %>% 
  as.data.frame() %>%
  rownames_to_column() %>% 
  setNames(c("År","R-squared")) %>% 
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}
compRsq(models1)

# compare RMSE across years
compRMSE <- function(m) {
  m %>% 
  #map(summary) %>% 
  #map_dbl("sigma") %>% 
  map_dbl(~sqrt(mean(residuals(.x)^2))) %>% 
  as.data.frame() %>%
  rownames_to_column() %>% 
  setNames(c("År","RMSE")) %>% 
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}
compRMSE(models1)

```

#### Random intercept kön

```{r}
models1b <- df2 %>% 
  split(.$ar) %>%
  map(~ lmer(Utagerande ~ Parenting + (1|Kön), data = .))
library(broom.mixed)
models1b %>% 
  map(broom.mixed::tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 4), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  kbl_rise()

lmer1 <- df2 %>% 
  filter(ar == 2020) %>%
  lmer(Utagerande ~ Parenting + (1|Kön), data = .)
lm1k <- df2 %>% 
  filter(ar == 2020) %>%
  lm(Utagerande ~ Parenting + Kön, data = .)
AIC(lmer1,lm1k)
```


#### Uppdelat på kön

```{r}

modelsP <- df2 %>%
  filter(Kön == "Pojke") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

modelsF <- df2 %>%
  filter(Kön == "Flicka") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

compEstimatesG <- function(m,n,filename) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write_csv(.,filename) 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}
compEstimatesG(models1,3,"Samband/compEstimates.csv")
compEstimatesG(modelsP,2,"Samband/compEstimatesPojkar.csv")
compEstimatesG(modelsF,2,"Samband/compEstimatesFlickor.csv")

```
#### Tabell
```{r}
allEstimates <- read_csv("Samband/compEstimates.csv") %>% 
  select(!ends_with("KönPojke")) %>% 
  add_column(Respondent = 'Alla')
fEstimates <- read_csv("Samband/compEstimatesFlickor.csv") %>% 
  add_column(Respondent = 'Flickor')
pEstimates <- read_csv("Samband/compEstimatesPojkar.csv") %>% 
  add_column(Respondent = 'Pojkar')

aEstimates <- rbind(allEstimates,fEstimates,pEstimates) %>% 
  janitor::clean_names(case = "snake")

aEstimates %>% 
  group_by(respondent) %>% 
  summarise(medel_intercept = mean(estimate_intercept),
            sd_intercept = sd(estimate_intercept),
            max_intercept = max(estimate_intercept),
            min_intercept = min(estimate_intercept),
            medel_parenting = mean(estimate_parenting),
            sd_parenting = sd(estimate_parenting),
            max_parenting = max(estimate_parenting),
            min_parenting = min(estimate_parenting)
            ) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3))) %>% 
  kbl_rise()

```

#### Tabell standardiserad
```{r}
library(datawizard)
compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

models1 %>% 
  map(datawizard::standardize) %>% 
  map(tidy) %>% 
  bind_rows() %>% 
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 3), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write.csv(.,"Samband/StdEstimates.csv") 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')

#quantile regression

```


#### Plots
```{r}
aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_intercept, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(color = respondent)) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting)) +
  scale_y_continuous(limits = c(-4,4)) +
  scale_x_continuous(limits = c(-4,4)) +

  aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(data = aEstimates %>% filter(respondent == "Alla"),
              aes(intercept = mean(estimate_intercept), slope = mean(estimate_parenting)),
              alpha = 0.86, color = "blue", linetype = 2, linewidth = 2) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
```

#### Plot 2
```{r}

library(ggside)
corSidePlot <- function(data, x, y, smooth = "lm", color) {
  
  data %>%
    ggplot(aes(x = {{ x }}, y = {{ y }}, color = {{ color }})) +
    geom_point2(size = 3, alpha = 0.7) +
    geom_smooth(method = smooth) +
    geom_xsidedensity(aes(y = after_stat(density))) +
    geom_ysidedensity(aes(x = after_stat(density))) +
    geom_xsidehistogram(aes(y = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
    geom_ysidehistogram(aes(x = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
}

df2 %>% 
  corSidePlot(., Utagerande, Parenting)

```

::: panel-tabset
##### 2020
```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2018
```{r}
df2 %>% 
  filter(ar == 2018) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2016
```{r}
df2 %>% 
  filter(ar == 2016) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2014
```{r}
df2 %>% 
  filter(ar == 2014) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
:::

### Kvantil regression
```{r}
library(quantreg)
lq1 <- rq(Utagerande ~ Parenting,
  data = df2, tau = 0.5
)
lm1 <- lm(Utagerande ~ Parenting,
  data = df2
)
AIC(lm1, lq1)
tidy(lm1)
tidy(lq1)

ggplot(df2, aes(Utagerande, Parenting)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", se = T, color = "blue", linewidth = 2) +
  geom_quantile(quantiles = 0.5, color = "red", linewidth = 2) +
  geom_quantile(
    color = "orange", alpha = 0.6,
    quantiles = seq(.1, .9, by = 0.1)
  ) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  )
```


### LMM Utagerande 2
```{r}
models2 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .))

compEstimates(models2,5)
sumEstimates(models2)
compRsq(models2)
```

#### Standardiserade effektstorlekar
```{r}
#df2 %>%
#  split(.$ar) %>%
#  map(~ emmeans(lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)), "Parenting")

m2s <- df2 %>% 
  filter(ar == 2016) %>% 
  lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)

emmeans(m2s, "Parenting")
#eff_size(m2emm, edf = 6041, sigma=sigma(m2s))
# borde gå att skriva en funktion för emmeans som går igenom varje år
```


### Utagerande och kriminalitet

#### Antal brott
```{r}
items.brott <- df %>% 
  select(starts_with("f75")) %>% 
  names()

df2 <- df2 %>% 
  mutate(AntalBrott = rowSums(across(all_of(items.brott)), na.rm = T))

df2 %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_bar(fill = RISEprimGreen)
```

#### Test av olika modeller

##### Vanlig poisson regression
```{r}
brott.poi <- glm(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020),
            family = poisson)
summary(brott.poi)
```

##### Negative binomial
```{r}
library(MASS)
brott.nb <- glm.nb(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott.nb)
```


##### Zero-inflated poisson
```{r}
brott.zi <- pscl::zeroinfl(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott.zi)
```

##### Hurdle negative binomial
```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Kön,
                 dist="negbin", 
                 data = df2 %>% filter(ar == 2020))
summary(brott.hrd)
```

##### AIC jämförelse
```{r}
AIC(brott.poi,brott.nb,brott.zi,brott.hrd) %>% 
  arrange(AIC)
```
Hurdle model har lägst AIC, följd av negative binomial.

#### Visualisering hurdle model
```{r}
predicted <- estimate_expectation(brott2, data = "grid")
plot(predicted) + 
  scale_color_manual(values = RISEpalette1[c(1,5)]) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Hurdle negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
# library(ggeffects)
# pred <- ggpredict(brott2, terms = c("Utagerande","Kön"))
# ggplot(pred, aes(x = x, y = predicted, colour = group)) +
#   geom_line(linewidth = 1.5) +
#   geom_point2() +
#   scale_color_manual(values = RISEpalette1[c(1,5)]) +
#   xlab("Antal självrapporterade brott") +
#   ylab("Indexvärde utagerande")
```

#### Visualisering negative binomial
```{r}
predicted.nb <- estimate_expectation(brott.nb, data = "grid")
plot(predicted.nb) + 
  scale_color_manual(values = RISEpalette1[c(1,5)], aesthetics = c("color","fill")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
```


#### Dikotomiserat utfall
Vi kodar en variabel där antal brott 0-2 = 0, och 3 eller fler blir 1.
```{r}
df <- df %>% 
  mutate(BrottDik = car::recode(AntalBrott,"0:2=0;3:19=1", as.factor = FALSE))

brott.dik <- glm(BrottDik ~ Utagerande + Parenting, 
            data = df %>% filter(Kön == "Pojke"),
            family = binomial)
modelsummary(brott.dik)
```

```{r}
plot(parameters(brott.dik))

predicted <- estimate_expectation(brott.poi.dik, data = "grid")
plot(predicted) +
  scale_color_manual(values = RISEpalette1[c(1,5)], 
                     aesthetics = c("fill","color")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Logistic regression prediction model")

### only for linear models:
# check <- check_normality(brott0)
# plot(check, type = "qq")
```

```{r}
# augment(brott.poi.dik) %>% 
#   filter(BrottDik == 1) %>% 
#   select(Utagerande) %>% 
#   summary()

augment(brott.poi.dik) %>%
  ggplot(aes(x = Utagerande, fill = BrottDik, group = BrottDik)) +
  geom_density(alpha = 0.7) +
  geom_vline(aes(xintercept = 0.9), color = "red", linetype = 2) +
  theme_bw() +
  scale_fill_viridis_c()
  
```

### Machine Learning modeling

#### Logistic penalized regression

```{r}
library(tidymodels)
library(dotwhisker)
library(vip)         # for variable importance plots
library(ranger)
df2$BrottDik2 <- factor(df2$BrottDik, levels = c(0,1),
                        labels = c("Låg","Hög"))

ml_vars <- c("BrottDik2","Utagerande","Kön","Parenting","Community","SkolaNegativ")

df3 <- df2 %>% 
  dplyr::select(any_of(ml_vars),ar) %>% 
  na.omit()

splits <- initial_validation_split(df3, strata = ar)
df_train <- training(splits)
df_test  <- testing(splits)
val_set <- initial_validation_split(df_train, 
                            strata = ar, 
                            #prop = c(0.8,0.2)
                            )
df_fold <- vfold_cv(df_train, v = 10)
```

```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")


lr_fit <- 
  lr_mod %>% 
  fit(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)

lr_recipe <- 
  recipe(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())# %>% 
  #step_normalize(all_numeric_predictors())

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
#| eval: true
#lr_splits <- vfold_cv(df_other, v = 10, strata = ar)
#_res <- tune_grid(lr_mod, ames_rec, resamples = cv_splits, grid = spline_grid)

#lr_reg_grid <- tibble(penalty = 10^seq(-5, -1, length.out = 40))
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)

lr_res <- 
  tune_grid(lr_workflow,
            resamples = df_fold,
            grid = penalty_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# lr_res <-
#   lr_workflow %>%
#   tune_grid(val_set,
#             grid = penalty_grid,
#             control = control_grid(save_pred = TRUE),
#             metrics = metric_set(roc_auc))

lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC") +
  scale_x_log10(labels = scales::label_number())

top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 
top_models

lr_best <- lr_res %>% 
  select_best()

lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(BrottDik2, `.pred_Hög`) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```


```{r}
#| eval: true

last_lr_mod <- 
  logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")

last_lr_workflow <- 
  lr_workflow %>% 
  update_model(last_lr_mod)

last_lr_fit <- 
  last_lr_workflow %>% 
  last_fit(splits)

last_lr_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

## Psy

```{r}
ml_vars2 <- c("PsykSomBesv","Utagerande","Kön","Parenting","Community","SkolaNegativ")

df.ml <- df2 %>% 
  dplyr::select(any_of(ml_vars2),ar) %>% 
  na.omit()

splits <- initial_split(df.ml, strata = ar)
df_train <- training(splits)
df_test  <- testing(splits)
val_set <- validation_split(df_train, 
                            strata = ar, 
                            prop = 0.80)
df_fold <- vfold_cv(df_train, v = 10)
```

```{r}
lm_mod <- 
  linear_reg() %>% 
  set_engine("lm")

lm_fit <- 
  lm_mod %>% 
  fit(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ + ar, data = df_train)

# lm_fit %>% 
#   extract_fit_engine() %>% 
#   plot()

tidy(lm_fit) %>% 
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))

lm_fit %>% 
  extract_fit_engine() %>% 
  vip(num_features = 20)
```

```{r}
ref_data <- df2 %>% 
  group_by(ar,Kön) %>% 
  summarise(Utagerande = mean(Utagerande, na.rm = T),
            Parenting = mean(Parenting, na.rm = T),
            Community = mean(Community, na.rm = T),
            SkolaNegativ = mean(SkolaNegativ, na.rm = T)) %>% 
  ungroup()

# add set of rows for 2024
ref_data <- rbind(ref_data,ref_data[(nrow(ref_data)-1):nrow(ref_data),]) %>% tail()
#ref_data$ar <- rep(c(årtal,2022,2024), each = 2)

mean_pred <- predict(lm_fit, new_data = ref_data)
conf_int_pred <- predict(lm_fit, 
                         new_data = ref_data, 
                         type = "conf_int")


plot_data <- 
  ref_data %>% 
  bind_cols(mean_pred) %>% 
  bind_cols(conf_int_pred)

ggplot(plot_data, aes(x = ar, color = Kön)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "psy besv")

#new_data <- ref_data %>% 
#  select(ar,)
```


```{r}
lm_recipe <- 
  recipe(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())

lm_workflow <- 
  workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(lm_recipe)


```


```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

# https://www.tmwr.org/workflow-sets
#library(rules)
#library(baguette)
linear_reg_spec <- 
   linear_reg(penalty = tune(), mixture = tune()) %>% 
   set_engine("glmnet")

nnet_spec <- 
   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
   set_engine("nnet", MaxNWts = 2600) %>% 
   set_mode("regression")

cart_spec <- 
   decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
   set_engine("rpart") %>% 
   set_mode("regression")

bag_cart_spec <- 
   bag_tree() %>% 
   set_engine("rpart", times = 50L) %>% 
   set_mode("regression")

xgb_spec <- 
   boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
              min_n = tune(), sample_size = tune(), trees = tune()) %>% 
   set_engine("xgboost") %>% 
   set_mode("regression")

nnet_param <- 
   nnet_spec %>% 
   extract_parameter_set_dials() %>% 
   update(hidden_units = hidden_units(c(1, 27)))

```

```{r}
nnet_fit <-
  nnet_spec %>% 
  fit(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)
```


```{r}
lr_fit <- 
  lr_mod %>% 
  fit(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)

lr_recipe <- 
  recipe(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())# %>% 
  #step_normalize(all_numeric_predictors())

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
#| eval: true
#lr_splits <- vfold_cv(df_other, v = 10, strata = ar)
#_res <- tune_grid(lr_mod, ames_rec, resamples = cv_splits, grid = spline_grid)

#lr_reg_grid <- tibble(penalty = 10^seq(-5, -1, length.out = 40))
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)

lr_res <- 
  tune_grid(lr_workflow,
            resamples = df_fold,
            grid = penalty_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# lr_res <-
#   lr_workflow %>%
#   tune_grid(val_set,
#             grid = penalty_grid,
#             control = control_grid(save_pred = TRUE),
#             metrics = metric_set(roc_auc))

lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 
top_models

lr_best <- lr_res %>% 
  select_best()

lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(BrottDik2, `.pred_Hög`) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```


```{r}
#| eval: true

last_lr_mod <- 
  logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")

last_lr_workflow <- 
  lr_workflow %>% 
  update_model(last_lr_mod)

last_lr_fit <- 
  last_lr_workflow %>% 
  last_fit(splits)

last_lr_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

## Programvara som använts

```{r}
#| label: packagesv
pkgs <- cite_packages(
  cite.tidyverse = TRUE,
  output = "table",
  bib.file = "grateful-refs.bib",
  include.RStudio = TRUE,
  out.dir = getwd()
)
formattable(pkgs,
  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
)
```

## Referenser
