---
title: "Samband mellan variabler"
subtitle: "Tvärsnittsdata över tid från Stockholmsenkäten"
title-block-banner: "#009ca6"
title-block-banner-color: "#FFFFFF"
author: 
  name: Magnus Johansson
  affiliation: RISE Research Institutes of Sweden
  affiliation-url: https://www.ri.se/sv/vad-vi-gor/expertiser/kategoriskt-baserade-matningar
  orcid: 0000-0003-1669-592X
date: last-modified
format: 
  html:
    toc: true
    toc-depth: 5
    toc-title: "Innehållsförteckning"
    embed-resources: true
    standalone: true
    page-layout: full
    mainfont: 'Lato'
    monofont: 'Roboto Mono'
    code-overflow: wrap
    code-tools: true
    code-fold: true
    number-sections: true
    fig-dpi: 96
    layout-align: left
    linestretch: 1.6
    theme: materia
    link-external-newwindow: true
execute:
  echo: true
  warning: false
  message: false
  cache: true
editor_options: 
  markdown: 
    wrap: 72
  chunk_output_type: console
bibliography: grateful-refs.bib
---

```{r}
library(tidyverse)
library(arrow)
library(knitr)
# library(lme4)
# library(broom)
# library(formattable)
# library(grateful)
# library(GGally)
# #library(ggiraph)
# library(ggdist)
# library(pscl)
# library(car)
# library(easystats)
# #library(emmeans)
library(marginaleffects)
library(modelsummary)
# library(kableExtra)
# library(glue)
# library(lavaan)
# library(lavaanPlot)
# library(quantreg)
library(readxl)
# library(MASS)
# library(patchwork)


### some commands exist in multiple packages, here we define preferred ones that are frequently used
select <- dplyr::select
count <- dplyr::count
recode <- car::recode
rename <- dplyr::rename

### set up color palette based on RISE guidelines
RISEprimGreen <- "#009ca6"
RISEprimRed <- "#e83c63"
RISEprimYellow <- "#ffe500"
RISEprimGreenMid <- "#8dc8c7"
RISEprimRedMid <- "#f5a9ab"
RISEprimYellowMid <- "#ffee8d"
RISEprimGreenLight <- "#ebf5f0"
RISEprimRedLight <- "#fde8df"
RISEprimYellowLight <- "#fff7dd"
RISEcompPurple <- "#482d55"
RISEcompGreenDark <- "#0e4e65"

# create a wide palette based on RISE colors
RISEpalette1 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(6)
# "#009CA6" "#5C758B" "#B94F70" "#EC5D4F" "#F5A127" "#FFE500"
RISEpalette2 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(10)

theme_rise <- function(fontfamily = "Lato", axissize = 13, titlesize = 15, margins = 12, axisface = "plain", panelDist = 0.6, ...) {
  theme_minimal() + 
    theme(text = element_text(family = fontfamily), 
          axis.title.x = element_text(margin = margin(t = margins), size = axissize), 
          axis.title.y = element_text(margin = margin(r = margins), size = axissize), 
          plot.title = element_text(face = "bold", size = titlesize), 
          axis.title = element_text(face = axisface), 
          plot.caption = element_text(face = "italic"), 
          legend.text = element_text(family = fontfamily), 
          legend.background = element_rect(color = "lightgrey"), 
          strip.background = element_rect(color = "lightgrey"), 
          panel.spacing = unit(panelDist, "cm", data = NULL), 
          panel.border = element_rect(color = "grey", fill = NA), ...)
}
# set theme default for the session/document
theme_set(theme_rise())

### RISE color palettes 
# the two palettes below have been checked for color blindness compatibility using library(colorblindcheck) 
RISEpalette8 <- c("#009CA6", "#428092", "#84657F", "#C6496C", "#EB5454", "#F18438", "#F8B41C", "#FFE500") 
RISEpalette6 <- c("#009CA6", "#5C758B", "#B94F70", "#EC5D4F", "#F5A127", "#FFE500") 

### palettes can be created using the three RISE primary colors and changing the number at the end: 
# RISEpalette1 <- colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(6) 

# gender split colors, replace label based on your dataset
gender_colors <- c("Pojke" = "#F5A127", "Flicka" = "#009CA6")
# these can be used in ggplots as `+ scale_color_gender()` or `+ scale_fill_gender()`
scale_color_gender <- partial(scale_color_manual, values = gender_colors)
scale_fill_gender <- partial(scale_fill_manual, values = gender_colors)

DIDcolorsGGYR <- c("lightgrey","#509B8E", "#E2C578", "#DB7358")
DIDcolorsRYGG <- c("#DB7358", "#E2C578", "#509B8E", "lightgrey")

kbl_rise <- function(data, tbl_width = 65, fontsize = 14, fontfamily = "Arial",
                     options = c("striped", "hover"), ...) {
  kbl(data, booktabs = T, escape = F,
      table.attr = glue("data-quarto-disable-processing='true' style='width:{tbl_width}%;'")) %>%
    kable_styling(
      bootstrap_options = options,
      position = "left",
      full_width = T,
      font_size = fontsize,
      fixed_thead = T,
      latex_options = c("striped", "scale_down"),
      ...
    ) %>%
    row_spec(0, bold = T) %>%
    kable_classic(html_font = fontfamily)
}


# read data
datafolder <- "~/Library/CloudStorage/OneDrive-SharedLibraries-RISE/SHIC - Data i Dialog - Data i Dialog/data/"

df.all <- read_parquet(paste0(datafolder,"DID_klart/2024-09-12_ScoredRev.parquet"))

årtal <- c(2006, 2008, 2010, 2012, 2014, 2016, 2018, 2020,2022,2024)
sthlm.index.all <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv","Wellbeing")

sthlm.index <- c("Utagerande","SkolaNegativ","Parenting","Community","PsykSomBesv","SkolaPositiv")

df <- df.all %>%
  filter(ar > 2004) %>%
  filter(ARSKURS == "Åk 9") %>% 
  filter(Kön %in% c("Pojke","Flicka")) %>% 
  rename(År = ar,
         Årskurs = ARSKURS,
         Kommun = DIDkommun)



## riskgruppsindelningar

# läs in gränsvärden
rslimits <- read_csv("Samband/2024-09-23_rslimitsNoRev.csv")
rslimits.prot <- read_csv("Samband/2024-09-23_protective.csv")

# skapa nya variabler för respektive indexvärde
df <- df %>% 
  mutate(riskUtagerande = case_when(Utagerande < rslimits$Utagerande[1] ~ "Låg risk",
                                    Utagerande > rslimits$Utagerande[2] ~ "Förhöjd risk",
                                    Utagerande <= rslimits$Utagerande[2] & Utagerande >= rslimits$Utagerande[1] ~ "Något förhöjd risk")) %>% 
  mutate(riskSkolaNegativ = case_when(SkolaNegativ < rslimits$SkolaNegativ[1] ~ "Låg risk",
                                      SkolaNegativ > rslimits$SkolaNegativ[2] ~ "Förhöjd risk",
                                      SkolaNegativ <= rslimits$SkolaNegativ[2] & SkolaNegativ >= rslimits$SkolaNegativ[1] ~ "Något förhöjd risk")) %>%
  mutate(riskParenting = case_when(Parenting < rslimits$Parenting[1] ~ "Låg risk",
                                   Parenting > rslimits$Parenting[2] ~ "Förhöjd risk",
                                   Parenting <= rslimits$Parenting[2] & Parenting >= rslimits$Parenting[1] ~ "Något förhöjd risk")) %>%
  mutate(riskCommunity = case_when(Community < rslimits$Community[1] ~ "Låg risk",
                                   Community > rslimits$Community[2] ~ "Förhöjd risk",
                                   Community <= rslimits$Community[2] & Community >= rslimits$Community[1] ~ "Något förhöjd risk")) %>%
  mutate(riskPsykSomBesv = case_when(PsykSomBesv < rslimits$PsykSomBesv[1] ~ "Låg risk",
                                     PsykSomBesv > rslimits$PsykSomBesv[2] ~ "Förhöjd risk",
                                     PsykSomBesv <= rslimits$PsykSomBesv[2] & PsykSomBesv >= rslimits$PsykSomBesv[1] ~ "Något förhöjd risk")) %>%
  mutate(skyddSkolaPositiv = case_when(SkolaPositiv < rslimits.prot$SkolaPositiv[2] ~ "<85",
                                      SkolaPositiv > rslimits.prot$SkolaPositiv[2] ~ "Förhöjt skydd")) %>% 
  mutate(across(starts_with("risk"), ~ factor(.x, levels = c("Låg risk", "Något förhöjd risk", "Förhöjd risk"))))



df.f <- df %>% 
  filter(Kön == "Flicka")

df.p <- df %>%
  filter(Kön == "Pojke")
```

## Deskriptiva data

Vi har tagit fram indexvärden för flera faktorer, och börjar med att titta på hur det ser ut med antal svar per år och index, samt andel missing data. Det krävs svar på minst fem ingående frågor för att ett indexvärde ska beräknas med tillförlitlighet, så de som svarat på färre än fem saknar indexvärde.

Vi tittar först enbart på årskurs 9 eftersom de är intressanta som yngre målgrupp ur ett preventionsperspektiv. Vi inkluderar enbart individer som svarat antingen pojke eller flicka på frågan om könstillhörighet. 

Analyserna görs separat för pojkar och flickor. Enbart individer med kompletta svar på variabler som ingår i respektive analys tas med i analyserna i detta skede.

::: panel-tabset
### Antal svar per år och per kommun
```{r}
# check number of respondents per year
df %>%
  count(År) %>%
  rename(
    Antal = n
  ) %>%
  kable()

# per municipality
df %>%
  count(Kommun) %>%
  rename(
    Antal = n
  ) %>%
  arrange(desc(Antal)) %>% 
  kable()
  
```
### Fördelat på kön
```{r}
df %>%
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(all_of(sthlm.index.all), names_to = "Index", values_to = "Indexvärde") %>% 
  group_by(År,Index,Kön) %>% 
  summarise(Antal = n()) %>% 
  ggplot(aes(x = År, y = Antal, color = Kön)) + 
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Antal respondenter per år",
       subtitle = "Fördelat på kön")
```
### Andel med missing data
```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(all_of(sthlm.index.all), 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  group_by(År,Index,Kön) %>%
  mutate(Svar = case_when(
    is.na(Indexvärde) ~ "För få svar",
    TRUE ~ "Har svar"
  )) %>% 
  count(Svar) %>% 
  mutate(Procent = round(100 * n / sum(n),1)) %>% 
  filter(Svar == "För få svar") %>% 
  ggplot(aes(x = År, y = Procent, color = Index, group = Index)) + 
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_x_continuous(guide = guide_axis(n.dodge = 1), breaks = årtal) +
  scale_y_continuous(limits = c(0,NA)) +
  labs(title = "Andel saknade svar per år",
       subtitle = "Fördelat på index") +
  ylab("Andel i procent") +
  facet_wrap(~Kön)

```
:::

### Fördelningar av indexvärden

Samtliga år tillsammans.

Höga värden av riskfaktorer = hög risk.

Höga värden av skyddsfaktor "Positiv skolanknytning" (SkolaPositiv) = högt skydd.

Höga värden av Välbefinnande/Wellbeing = högt välbefinnande.

```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(all_of(sthlm.index.all), 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  ggplot(aes(x = Indexvärde, fill = Kön)) +
  geom_histogram(alpha = 0.8) +
  scale_fill_gender() +
  facet_wrap(~Index) +
  labs(title = "Fördelning av indexvärden",
       subtitle = "2006-2022, pojkar och flickor, enbart åk 9",
       x = "Indexvärde",
       y = "Antal")
```

```{r}
df %>% 
  select(all_of(sthlm.index.all),År,Kön) %>% 
  pivot_longer(all_of(sthlm.index.all), 
               names_to = "Index", 
               values_to = "Indexvärde") %>% 
  mutate(Index = factor(Index, levels = sthlm.index.all)) %>% 
  ggplot(aes(y = Indexvärde, x = Index, fill = Kön)) +
  geom_boxplot(outlier.shape = NA) +
  scale_fill_gender() +
  labs(title = "Fördelning av indexvärden",
       subtitle = "2006-2022, pojkar och flickor, enbart åk 9",
       x = "Index",
       y = "Indexvärde")
```

### Fördelning av riskgrupp

```{r}
df %>% 
  select(starts_with("risk")) %>% 
  pivot_longer(everything()) %>%
  separate_wider_delim(name, names = c(NA,"Riskgrupp"), delim = "isk") %>% 
  count(Riskgrupp,value) %>%
  mutate(value = factor(value, levels = c("Låg risk","Något förhöjd risk","Förhöjd risk"),
                            labels = c("Låg risk","Något förhöjd risk","Förhöjd risk")
                        )) %>% 
  mutate(value = forcats::fct_rev(value)) %>% 
  
  ggplot(aes(x = Riskgrupp, y = n, fill = value)) +
  geom_col() +
  geom_text(aes(label = n),
            position = position_stack(vjust = .5)) +
  scale_fill_manual('Riskgrupp', values = DIDcolorsRYGG) +
  labs(title = "Fördelning av riskgrupp",
       subtitle = "2006-2024, pojkar och flickor, enbart åk 9",
       x = "Riskfaktor",
       y = "Antal") +
  update_geom_defaults("text", list(family = "Lato"))
  
```

## Additive Bayesian Network analysis

Denna typ av modeller fungerar enbart med kontinuerliga, binomiala, eller poisson data.

Vi testar att dikotomisera `Hur länge har du bott i Sverige?` = F5 samt `Vilken högsta utbildning har din mamma/pappa?` = f6ab.

```{r}
library(abn)

# filter variables to include in network
mydata <- 
  df.f %>% 
  mutate(F5 = factor(F5, levels = c("Mindre än 5 år","5-9 år", "10 år eller mer", "Hela mitt liv"))) %>%
  # rename(`Hur länge har du bott i Sverige?` = F5,
  #        `Vilken högsta utbildning har din mamma/pappa?` = f6ab,
  #        `Vad bor du i för typ av bostad?` = F7)
  mutate(mobbad = case_when(f60b == 1 ~ "Ja",
                            f60c == 1 ~ "Ja",
                            f60d == 1 ~ "Ja",
                            f60e == 1 ~ "Ja",
                            f60f == 1 ~ "Ja",
                            f60g == 1 ~ "Ja",
                            f60h == 1 ~ "Ja",
                            f60i == 1 ~ "Ja",
                            F63 == 1 ~ "Ja",
                            f60a == 1 ~ "Nej",
                            TRUE ~ NA
  )) %>%
  mutate(mobbad = factor(mobbad)) %>%
  mutate(bott = case_when(F5 == "Hela mitt liv" | F5 == "10 år eller mer" ~ "10år+",
                          F5 == "5-9 år" | F5 == "Mindre än 5 år" ~ "0-9 år")) %>% 
  mutate(bott = factor(bott)) %>% 
  mutate(f_utb = case_when(f6ab == "Universitet och högskola" | f6ab == "Gymnasium" ~ "Gymnasium+",
                           f6ab == "Folkskola eller grundskola (max 9 år i skolan)" ~ "Max 9 år skola")) %>% 
  mutate(f_utb = factor(f_utb)) %>% 
  mutate(year = factor(År)) %>% 
  select(all_of(sthlm.index.all),f_utb,mobbad,bott,year) %>% 
  select(!Wellbeing) %>% 
  na.omit() %>% 
  as.data.frame()
```

börjar med en simpel modell med fyra variabler

```{r}
mydists0 <- list(SkolaNegativ = "gaussian",
                Parenting = "gaussian",
                PsykSomBesv = "gaussian",
                mobbad = "binomial"
                )

mydata0 <- mydata %>% 
  select(SkolaNegativ,Parenting,PsykSomBesv,mobbad,year) %>% 
  as.data.frame()

sc0 <- buildScoreCache(
  data.df = mydata0,
  data.dists = mydists0,
  #dag.banned = banmat,
  group.var = "year",
  method = "bayes",
  max.parents = 2
)

mp.sc0 <- mostProbable(score.cache = sc0,
                            max.parents = 2)

fit.sc1.mp <- fitAbn(object = mp.sc0,
                        method = "bayes",
                        max.parents = 2)
plot(fit.sc1.mp)
```



```{r}

mydists <- list(Utagerande = "gaussian",
                SkolaNegativ = "gaussian",
                Parenting = "gaussian",
                Community = "gaussian",
                PsykSomBesv = "gaussian",
                SkolaPositiv = "gaussian",
                f_utb = "binomial",
                mobbad = "binomial",
                bott = "binomial"
                )

### first
# https://r-bayesian-networks.org/reference/buildScoreCache.html

banmat <- matrix(0, nrow = length(mydists), ncol = length(mydists), dimnames = list(names(mydists), names(mydists)))

# inget påverkar hur länge man bott i SE, rimligtvis
banmat[9,] <- 1
banmat[9, 9] <- 0

# PSB bör ej påverka trivsel i närområdet, föräldrarnas utb
banmat[4, 5] <- 1
banmat[7, 5] <- 1

# fldr utb bör ej påverka hur man trivs i boendeområdet 
banmat[4, 7] <- 1

# Utagerande borde inte påverka föräldrarnas utbildning 
banmat[7, 1] <- 1

# community ej f_utb
banmat[7, 4] <- 1

banmat

sc1 <- buildScoreCache(
  data.df = mydata,
  data.dists = mydists,
  dag.banned = banmat,
  #group.var = "PID",
  method = "bayes",
  max.parents = 2
)

#saveRDS(sc1, "sc1.Rdata")

### then two options for deciding which model to go with
# https://r-bayesian-networks.org/reference/mostProbable.html

mp.sc1 <- mostProbable(score.cache = sc1,
                            max.parents = 2)


# https://r-bayesian-networks.org/reference/searchHillClimber.html
hc.sc1 <- searchHillClimber(score.cache = sc1,
                            max.parents = 2)

sh.sc1 <- searchHeuristic(score.cache = sc1,
                            max.parents = 2)
                         
# myfit.sc1.mp <- fitAbn(object = mp.sc1,
#                         method = "mle",
#                         max.parents = 2)
# 
# myfit.sc1.hc <- fitAbn(object = hc.sc1,
#                         method = "mle",
#                         max.parents = 2)
# 
# myfit.sc1.sh <- fitAbn(object = sh.sc1,
#                         method = "mle",
#                         max.parents = 2)

myfit.sc1.mp <- fitAbn(object = mp.sc1,
                        method = "bayes",
                        max.parents = 2)

myfit.sc1.hc <- fitAbn(object = hc.sc1,
                        method = "bayes",
                        max.parents = 2)



plot(myfit.sc1.mp)

plot(myfit.sc1.hc)

# infoDag(dag.sc1)
# infoDag(hc.sc1)
```

nested in years

```{r}
mydata2 <- 
  df.f %>% 
    mutate(F5 = factor(F5, levels = c("Mindre än 5 år","5-9 år", "10 år eller mer", "Hela mitt liv"))) %>%
  # rename(`Hur länge har du bott i Sverige?` = F5,
  #        `Vilken högsta utbildning har din mamma/pappa?` = f6ab,
  #        `Vad bor du i för typ av bostad?` = F7)
    mutate(mobbad = case_when(f60b == 1 ~ "Ja",
                            f60c == 1 ~ "Ja",
                            f60d == 1 ~ "Ja",
                            f60e == 1 ~ "Ja",
                            f60f == 1 ~ "Ja",
                            f60g == 1 ~ "Ja",
                            f60h == 1 ~ "Ja",
                            f60i == 1 ~ "Ja",
                            F63 == 1 ~ "Ja",
                            f60a == 1 ~ "Nej",
                            TRUE ~ NA
  )) %>%
  mutate(mobbad = factor(mobbad)) %>%
    mutate(bott = case_when(F5 == "Hela mitt liv" | F5 == "10 år eller mer" ~ "10år+",
                            F5 == "5-9 år" | F5 == "Mindre än 5 år" ~ "0-9 år")) %>% 
    mutate(bott = factor(bott)) %>% 
 mutate(f_utb = case_when(f6ab == "Universitet och högskola" | f6ab == "Gymnasium" ~ "Gymnasium+",
                            f6ab == "Folkskola eller grundskola (max 9 år i skolan)" ~ "Max 9 år skola")) %>% 
    mutate(f_utb = factor(f_utb)) %>% 
  mutate(year = factor(År)) %>% 
  select(all_of(sthlm.index.all),f_utb,mobbad,bott,year) %>% 
  select(!Wellbeing) %>% 
  na.omit() %>% 
  as.data.frame()


sc2 <- buildScoreCache(
  data.df = mydata2,
  data.dists = mydists, 
  group.var = "year",
  method = "bayes",
  max.parents = 2
)
```

```{r}
mp.sc2 <- mostProbable(score.cache = sc2,
                            max.parents = 2)


# https://r-bayesian-networks.org/reference/searchHillClimber.html
hc.sc2 <- searchHillClimber(score.cache = sc2,
                            max.parents = 2)

myfit.sc2.mp <- fitAbn(object = mp.sc2,
                        method = "bayes",
                        max.parents = 2)

myfit.sc2.hc <- fitAbn(object = hc.sc2,
                        method = "bayes",
                        max.parents = 2)



plot(myfit.sc2.mp)

plot(myfit.sc2.hc)
```


## bnlearn

```{r}
library(bnlearn)
library(qgraph) 
```

```{r}
BNgs <- gs(mydata) # this performs the algorithm 
#qgraph(BNgs) # this plots the network

BSTgs <- boot.strength(mydata, # this includes the data set 
                     R = 200, # this sets the number of boots 
                     algorithm = "gs") # this sets the algorithm

plot(BSTgs)

BSTgs <- BSTgs[BSTgs$strength > 0.85 & # this sets the strength 
              BSTgs$direction > 0.5,] # this sets the minimum direction

avgnetGS <- averaged.network(BSTgs,
                            threshold = 0.85) ## compute the average network

qgraph(avgnetGS, layout="circle")
```

no output... let's try other methods

```{r}
BNiamb <- iamb(mydata) # this performs the algorithm 
#qgraph(BNiamb) # this plots the network

BSTiamb <- boot.strength(mydata, # this includes the data set 
                     R = 200, # this sets the number of boots 
                     algorithm = "iamb") # this sets the algorithm

plot(BSTiamb)

BSTiamb <- BSTiamb[BSTiamb$strength > 0.85 & # this sets the strength 
              BSTiamb$direction > 0.5,] # this sets the minimum direction

avgnetIAMB <- averaged.network(BSTiamb,
                            threshold = 0.85) ## compute the average network
qgraph(avgnetIAMB, layout="circle")
```
hill climbing
```{r}
BNhc <- hc(mydata) # this performs the algorithm 
#qgraph(BNhc) # this plots the network

BSThc<- boot.strength(mydata, # this includes the data set 
                     R = 200, # this sets the number of boots 
                     algorithm = "hc") # this sets the algorithm
plot(BSThc)
BSThc <- BSThc[BSThc$strength > 0.85 & # this sets the strength 
              BSThc$direction > 0.5,] # this sets the minimum direction

avgnetHC <- averaged.network(BSThc,
                            threshold = 0.85) ## compute the average network
qgraph(avgnetHC, layout="circle")
```


## Psykiska/psykosomatiska besvär

Vi utgår från att bristande föräldraskap, vantrivsel i skolan, och närsamhället är riskfaktorer.

### Flickor

Först visualisering av data utifrån kontinuerliga variabler

```{r}
df.f %>% 
  ggplot(aes(x = Parenting, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 

df.f %>% 
  ggplot(aes(x = SkolaNegativ, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 

df.f %>% 
  ggplot(aes(x = Community, y = PsykSomBesv)) +
  geom_point() +
  geom_smooth(se = TRUE) 
```

Sedan visualisering med riskgruppsindelning

```{r}
riskVSoutcome <- function(data,riskfactor,outcome,title) {
  data %>% 
    drop_na(riskfactor) %>% 
    ggplot(aes(x = !!sym(riskfactor), y = !!sym(outcome), color = !!sym(riskfactor), fill = !!sym(riskfactor))) +
    geom_jitter(alpha = 0.1, width = 0.2) +
    geom_boxplot(alpha = 0.7, width = 0.5, notch = T) +
    scale_color_manual('Riskgrupp', values = DIDcolorsGGYR[2:4], aesthetics = c("color","fill")) +
    labs(title = paste0(title),
         subtitle = "2006-2024, flickor åk 9",
         x = "Riskgrupp",
         y = "Psykiska/psykosomatiska besvär")
}

riskVSoutcome(df.f,"riskParenting","PsykSomBesv","Bristande föräldraskap")
riskVSoutcome(df.f,"riskSkolaNegativ","PsykSomBesv","Vantrivsel i skolan")
riskVSoutcome(df.f,"riskCommunity","PsykSomBesv","Närsamhälle risk")
```

Närsamhälle verkar inte ha någon påtaglig inverkan, medan vantrivsel i skolan och bristande föräldraskap visar tydligare skillnader.

#### Statistisk modellering

##### Med kontinuerliga variabler

```{r}
# ta bort individer med missing data på någon av variablerna eftersom de ändå exkluderas av lm() och vi vill kunna beräkna residualer manuellt.
df.fr <- df.f %>% 
  drop_na(PsykSomBesv,Parenting,SkolaNegativ,Community)

df.pr <- df.p %>% 
  drop_na(PsykSomBesv,Parenting,SkolaNegativ,Community)

psy1_f <- 
  df.fr %>% 
  lm(PsykSomBesv ~ Parenting + SkolaNegativ + Community, 
     data = .)
psy1_f_resids <- (psy1_f$fitted.values - df.fr$PsykSomBesv)
qqnorm(psy1_f_resids)
qqline(psy1_f_resids)

modelsummary(psy1_f, vcov = "HC3")
```

VIF is low, which is good. Residuals are non-normal. We can use a robust estimator (HC3 as implemented in [marginaleffects](https://marginaleffects.com/vignettes/uncertainty.html#robust-standard-errors)) to get more accurate standard errors.

```{r}
avg_slopes(psy1_f, vcov = "HC3")
plot_predictions(psy1_f, condition = "Parenting", vcov = "HC3") +
  coord_cartesian(ylim = c(-2,2))
```

Or use `lm_robust()`, which uses HC2.
```{r}
library(estimatr)

# https://declaredesign.org/r/estimatr/articles/getting-started.html

psy1r_f <-
  df.fr %>%
  lm_robust(PsykSomBesv ~ Parenting + SkolaNegativ + Community,
     data = .)
#  clusters = clust
psy1r_f_resids <- (psy1r_f$fitted.values - df.fr$PsykSomBesv)
qqnorm(psy1r_f_resids)
qqline(psy1r_f_resids)
```

#### Quantile regression

```{r}
library(quantreg)
psy1rq_f <- rq(data = df.fr,
   PsykSomBesv ~ Parenting + SkolaNegativ + Community)

psy1rq_f_resids <- (psy1rq_f$fitted.values - df.fr$PsykSomBesv)
qqnorm(psy1rq_f_resids)

psy2rq_f <- rq(data = df.fr,
   PsykSomBesv ~ Parenting + SkolaNegativ + Community,
   tau = c(0.25,0.5,0.75))

ggplot(df.fr, aes(PsykSomBesv, Parenting)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", se = T, color = "blue", linewidth = 2) +
  geom_quantile(quantiles = 0.5, color = "red", linewidth = 2) +
  geom_quantile(
    color = "orange", alpha = 0.6,
    quantiles = c(0.25,0.5,0.75)
  ) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  )
```

#### GAM skolaNeg

Linjär modell först, som jämförelse. Vi passar även på att testa interaktionseffekten mellan tid och SkolaNegativ.

```{r}
library(mgcv)
library(estimatr)
# we need the time variable to start at 1
df.fr <- df.fr %>% 
  mutate(year = År - 2005) %>% 
  mutate(yearF = factor(year))

df.pr <- df.pr %>% 
  mutate(year = År - 2005) %>% 
  mutate(yearF = factor(year))

# linear model for comparison, time as factor
psy1_lm <- lm(PsykSomBesv ~ yearF * SkolaNegativ,
              data = df.fr)
modelsummary(psy1_lm, vcov = "HC3")
plot_predictions(psy1_lm, "yearF", vcov = "HC3") +
  scale_x_discrete(labels = årtal)
plot_predictions(psy1_lm, "SkolaNegativ", vcov = "HC3")

# lm with time as continuous
psy1_lm2 <- lm(PsykSomBesv ~ year * SkolaNegativ,
              data = df.fr)
modelsummary(psy1_lm2, vcov = "HC3")
plot_predictions(psy1_lm2, "year", vcov = "HC3")
```

Väldigt liten interaktionseffekt mellan tid och SkolaNegativ, så vi bortser från den i nästa modell.

Jämför linjär och loess smoothad

```{r}
ggplot(df.fr) +
  aes(x = year, y = PsykSomBesv) +
  geom_smooth(method = "lm") +
  geom_smooth(method = "loess")
```


```{r}
psy1_gam <- gam(PsykSomBesv ~ s(year) + SkolaNegativ,
                data = df.fr)
modelsummary(psy1_gam)
plot_predictions(psy1_gam, "year")
plot_predictions(psy1_gam, "SkolaNegativ")
```

Utvecklingen över tid är helt klart inte linjär. SkolaNegativ används som linjär prediktor här, men är den det?

```{r}
psy_skolaneg_gam <- gam(PsykSomBesv ~ s(SkolaNegativ),
                data = df.fr)
plot_predictions(psy_skolaneg_gam, "SkolaNegativ")
psy_skolaneg_gam_pred <- predictions(psy_skolaneg_gam)
max(psy_skolaneg_gam_pred$estimate)
rslimits
```

Vi ser att högsta nivån för sambandet mellan SkolaNegativ och PSB är när SkolaNegativ är 1.1, men trenden börjar plana ut runt ca 1.0. Det distributionsbaserade gränsvärdet för "Förhöjd risk" är satt till 1.18. Med hänsyn till PSB bör det nog sänkas till 1.0-1.1.

Men vi behöver titta på sambandet över tid, d.v.s. köra gam() på varje mättillfälle

```{r}
psb_sn_gam <- map(seq(1,19,2), ~ gam(PsykSomBesv ~ s(SkolaNegativ),
                       data = df.fr %>% 
                         filter(year == .x)))

psb_sn_gam_preds <- map(1:10, ~ predictions(psb_sn_gam[[.x]]))

psb_sn_gam_max <- map(1:10, ~ max(psb_sn_gam_preds[[.x]]$estimate)) %>% 
  unlist()

psb_sn_gam_n <- map(1:10, ~ length(psb_sn_gam_preds[[.x]]$estimate)) %>% 
  unlist()

weighted.mean(psb_sn_gam_max, psb_sn_gam_n)
library(summarytools)
descr(psb_sn_gam_max, stats = c("min", "q1", "med", "q3", "max","mean"))
descr(psb_sn_gam_n, stats = c("min", "q1", "med", "q3", "max","mean"))
```

Viktat medelvärde från 10 mätningar blir 1.11, omfånget är 0.90 till 1.34.

```{r}
tibble("År" = seq(1,19,2) + 2005,
           `Antal svar` = psb_sn_gam_n,
           `Högsta värde` = psb_sn_gam_max) %>% 
  
  ggplot(aes(x = År, y = `Högsta värde`)) +
  geom_point(aes(size = `Antal svar`/1000)) +
  geom_line() +
  scale_x_continuous(breaks = årtal, minor_breaks = NULL) +
  scale_y_continuous(limits = c(0,2))
```

Respondenter som har predicerat värde på ca 1.1 på SkolaNegativ, vad har de för faktiskt värde på PSB?

```{r}
psy_skolaneg_gam_pred %>% 
  filter(estimate > 1.09) %>% 
  pull(PsykSomBesv) %>% 
  hist()

psy_skolaneg_gam_pred %>% 
  filter(estimate > 1.09) %>% 
  pull(PsykSomBesv) %>% 
  descr()
```

Stor spridning, vilket talar för försiktig tolkning, och kanske är vårt gränsvärde på 1.18 från distributionsbaserade 90:e percentilen förnuftigt. Gränsvärdet för PSB är 1.16.

Medianvärde för PSB bland denna subpopulation är 1.06. Vi tittar på hur det förhåller sig till samtliga data.

```{r}
hist(df.fr$PsykSomBesv)
abline(v = 1.06, col = "red")
descr(df.fr$PsykSomBesv)
rslimits
quantile(df.fr$PsykSomBesv, .82)
```




#### GAM fldr

Linjär modell först, som jämförelse. Vi passar även på att testa interaktionseffekten mellan tid och SkolaNegativ.

```{r}
# linear model for comparison
psy2_lm <- lm(PsykSomBesv ~ year * Parenting,
              data = df.fr)
modelsummary(psy2_lm)
plot_predictions(psy2_lm, "Parenting")

psy2_lm <- lm(PsykSomBesv ~ Parenting,
              data = df.fr)
modelplot(psy2_lm)

```

Väldigt liten interaktionseffekt mellan tid och Parenting, så vi bortser från den i nästa modell.

```{r}
psy2_gam <- gam(PsykSomBesv ~ s(year) + Parenting,
                data = df.fr)
modelsummary(psy2_gam)
plot_predictions(psy2_gam, "year")
plot_predictions(psy2_gam, "Parenting")
```

Utvecklingen över tid är helt klart inte linjär. Parenting används som linjär prediktor här, men är den det?

```{r}
psy_parenting_gam <- gam(PsykSomBesv ~ s(Parenting),
                data = df.fr)
plot_predictions(psy_parenting_gam, "Parenting")
psy_parenting_gam_pred <- predictions(psy_parenting_gam)
max(psy_parenting_gam_pred$estimate)
rslimits
```

Vi ser att högsta nivån för sambandet mellan SkolaNegativ och PSB är när SkolaNegativ är 1.1, men trenden börjar plana ut runt ca 1.0. Det distributionsbaserade gränsvärdet för "Förhöjd risk" är satt till 1.18. Med hänsyn till PSB bör det nog sänkas till 1.0-1.1.

Men vi behöver titta på sambandet över tid, d.v.s. köra gam() på varje mättillfälle

```{r}
psb_sn_gam <- map(seq(1,19,2), ~ gam(PsykSomBesv ~ s(SkolaNegativ),
                       data = df.fr %>% 
                         filter(year == .x)))

psb_sn_gam_preds <- map(1:10, ~ predictions(psb_sn_gam[[.x]]))

psb_sn_gam_max <- map(1:10, ~ max(psb_sn_gam_preds[[.x]]$estimate)) %>% 
  unlist()

psb_sn_gam_n <- map(1:10, ~ length(psb_sn_gam_preds[[.x]]$estimate)) %>% 
  unlist()

weighted.mean(psb_sn_gam_max, psb_sn_gam_n)
library(summarytools)
descr(psb_sn_gam_max, stats = c("min", "q1", "med", "q3", "max","mean"))
descr(psb_sn_gam_n, stats = c("min", "q1", "med", "q3", "max","mean"))
```

Viktat medelvärde från 10 mätningar blir 1.11, omfånget är 0.90 till 1.34.

```{r}
tibble("År" = seq(1,19,2) + 2005,
           `Antal svar` = psb_sn_gam_n,
           `Högsta värde` = psb_sn_gam_max) %>% 
  
  ggplot(aes(x = År, y = `Högsta värde`)) +
  geom_point(aes(size = `Antal svar`/1000)) +
  geom_line() +
  scale_x_continuous(breaks = årtal, minor_breaks = NULL) +
  scale_y_continuous(limits = c(0,2))
```

#### GAM fler variabler

```{r}
df.f.gam <- 
  df.f %>% 
  mutate(bott = factor(F5, levels = c("Mindre än 5 år","5-9 år", "10 år eller mer", "Hela mitt liv"))) %>%
  # rename(`Hur länge har du bott i Sverige?` = F5,
  #        `Vilken högsta utbildning har din mamma/pappa?` = f6ab,
  #        `Vad bor du i för typ av bostad?` = F7)
  mutate(mobbad = case_when(f60b == 1 ~ 1,
                            f60c == 1 ~ 1,
                            f60d == 1 ~ 1,
                            f60e == 1 ~ 1,
                            f60f == 1 ~ 1,
                            f60g == 1 ~ 1,
                            f60h == 1 ~ 1,
                            f60i == 1 ~ 1,
                            F63  == 1 ~ 1,
                            f60a == 1 ~ 0,
                            TRUE ~ NA
  )) %>%
  mutate(mobbad = factor(mobbad)) %>%
  #mutate(bott = case_when(F5 == "Hela mitt liv" | F5 == "10 år eller mer" ~ "10år+",
  #                        F5 == "5-9 år" | F5 == "Mindre än 5 år" ~ "0-9 år")) %>% 
  mutate(f_utb = factor(f6ab)) %>% 
  mutate(year = factor(År)) %>% 
  select(all_of(sthlm.index.all),f_utb,mobbad,bott,year,F70) %>% 
  select(!Wellbeing) %>% 
  mutate(fr_aktiv = car::recode(F70,"1=0;0=1", as.factor = T)) %>% 
  select(!F70) %>% 
  na.omit() %>% 
  as.data.frame()

# fr_aktiv = Brukar du delta i någon ledarledd fritidsaktivitet eller träning?, där 1 = ofta/ibland, och 0 = sällan/aldrig

# df.f.gam %>% 
#   count(F70)
```

```{r}
df.p.gam <- 
  df.p %>% 
  mutate(bott = factor(F5, levels = c("Mindre än 5 år","5-9 år", "10 år eller mer", "Hela mitt liv"))) %>%
  # rename(`Hur länge har du bott i Sverige?` = F5,
  #        `Vilken högsta utbildning har din mamma/pappa?` = f6ab,
  #        `Vad bor du i för typ av bostad?` = F7)
  mutate(mobbad = case_when(f60b == 1 ~ 1,
                            f60c == 1 ~ 1,
                            f60d == 1 ~ 1,
                            f60e == 1 ~ 1,
                            f60f == 1 ~ 1,
                            f60g == 1 ~ 1,
                            f60h == 1 ~ 1,
                            f60i == 1 ~ 1,
                            F63  == 1 ~ 1,
                            f60a == 1 ~ 0,
                            TRUE ~ NA
  )) %>%
  mutate(mobbad = factor(mobbad)) %>%
  #mutate(bott = case_when(F5 == "Hela mitt liv" | F5 == "10 år eller mer" ~ "10år+",
  #                        F5 == "5-9 år" | F5 == "Mindre än 5 år" ~ "0-9 år")) %>% 
  mutate(f_utb = factor(f6ab)) %>% 
  mutate(year = factor(År)) %>% 
  select(all_of(sthlm.index.all),f_utb,mobbad,bott,year,F70) %>% 
  select(!Wellbeing) %>% 
  mutate(fr_aktiv = car::recode(F70,"1=0;0=1", as.factor = T)) %>% 
  select(!F70) %>% 
  na.omit() %>% 
  as.data.frame()
```


Linjär modell

```{r}
psy0_f <- 
  lm(PsykSomBesv ~ Parenting, 
     data = df.f.gam)

glance(psy0_f)

modelplot(psy0_f, vcov = "HC3", coef_omit = "(Intercept)") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  scale_y_discrete(labels = c("Bristande föräldraskap")) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med riskfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall"
       ) +
  scale_x_continuous(breaks = seq(-0.4,0.5,0.1))
```


```{r}
psy1_f <- 
  lm(PsykSomBesv ~ Parenting + SkolaNegativ + Community, 
     data = df.f.gam)

modelsummary(psy1_f, vcov = "HC3")

glance(psy1_f)

modelplot(psy1_f, vcov = "HC3", coef_omit = "(Intercept)") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  coord_cartesian(xlim = c(-0.5,0.5)) +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  scale_y_discrete(labels = rev(c("Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med riskfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall"
       ) +
  scale_x_continuous(breaks = seq(-0.5,0.5,0.1))
```

```{r}
psy1_f2 <- 
  lm_robust(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott + fr_aktiv, 
            data = df.f.gam,
            clusters = year)

# robust LM
psy1_f2rlm <- 
  MASS::rlm(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott + fr_aktiv, 
            data = df.f.gam)

# get robust SE
library(sandwich)
library(lmtest) 
psy1_f2rlm_se <- coeftest(psy1_f2rlm,
                          vcov = vcovCL,
                          #type = "HC3",
                          df = 9,  # clusters - 1, if needed
                          cluster = ~year)
# and CI
#confint(psy1_f2rlm_se)

tidy(psy1_f2)%>% 
  mutate(across(where(is.numeric), ~ round(.x,3)))
tidy(psy1_f2rlm, conf.int = TRUE) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3)))
tidy(psy1_f2rlm_se, conf.int = TRUE) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3)))
```

rlm() verkar ge försiktigare resultat, och den ska också vara stabilare när det finns outliers.

```{r}

psy1_f2 <- psy1_f2rlm_se

modelsummary(psy1_f2)

modelplot(psy1_f2, coef_omit = "(Intercept)") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
    #scale_y_discrete(labels = c("Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap")) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med riskfaktorer")

modelplot(psy1_f2,
          coef_omit = "Intercept|bott|utb") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
    scale_y_discrete(labels = rev(c("Brukar delta i ledarledd\nfritidsaktivitet eller träning","Utsatt för någon typ\nav mobbning","Positiv skolanknytning","Utagerande/\nnormbrytande beteende","Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall",
              caption = str_wrap("Ej statistiskt signifikanta variabler är bortplockade ur figuren: Hur länge bott i Sverige; Föräldrarnas utbildningsnivå", 66)) +
  scale_x_continuous(breaks = seq(-0.4,0.5,0.1))

#modelplot(psy1_f2)
glance(psy1_f2)

library(performance)
check_collinearity(psy1_f2)
summary(psy1_f2)
# VIP = t-value
tidy(psy1_f2) %>% 
  mutate(statistic = abs(statistic),
         term = factor(term),
         term = fct_reorder(term,statistic)) %>% 
  filter(!term == "(Intercept)",
         statistic > 10) %>% 
  ggplot(aes(x = statistic, y = term)) +
  geom_col() +
  scale_y_discrete(labels = rev(c("Negativ skolanknytning","Brukar delta i ledarledd\nfritidsaktivitet eller träning","Utsatt för någon typ\nav mobbning","Bristande föräldraskap","Positiv skolanknytning","Utagerande/\nnormbrytande beteende"))) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       x = "T-värde från linjär regression",
       y = "")

lm_items <- data.frame(
  term = c(
    "Utagerande", "SkolaNegativ", "Parenting", "Community", "SkolaPositiv", "f_utb", "mobbad1", "bott",
    "fr_aktiv1"
  ),
  desc = c(
    "Utagerande/\nnormbrytande beteende", "Negativ skolanknytning",
    "Bristande föräldraskap", "Otryggt närsamhälle",
    "Positiv skolanknytning", "Föräldrarnas utbildningsnivå",
    "Utsatt för någon typ\nav mobbning", "Boendetid i Sverige",
    "Brukar delta i ledarledd\nfritidsaktivitet eller träning"
  )
)

tidy(psy1_f2, conf.int = TRUE)%>% 
  mutate(across(where(is.numeric), ~ round(.x,3)),
         term = factor(term)) %>% 
  filter(!term == "(Intercept)",
         p.value < .05) %>%
  left_join(lm_items, by = "term") %>% 
  mutate(desc = fct_reorder(desc, estimate)) %>% 
  
  ggplot(aes(x = estimate, y = desc, color = ifelse(estimate > 0, "green","red"))) +
  geom_point(size = 4) +
  geom_segment(aes(x = conf.low, xend = conf.high)) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
  #scale_y_discrete(labels = rev(c("Brukar delta i ledarledd\nfritidsaktivitet eller träning","Utsatt för någon typ\nav mobbning","Positiv skolanknytning","Utagerande/\nnormbrytande beteende","Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
  labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall",
       caption = str_wrap("Ej statistiskt signifikanta variabler är bortplockade ur figuren: Hur länge bott i Sverige; Föräldrarnas utbildningsnivå", 66),
       y = "") +
  scale_x_continuous(breaks = seq(-0.4,0.5,0.1))

```

GAM

```{r}
df.f.gam %>% 
  pivot_longer(c(Parenting,SkolaNegativ,Community,Utagerande,SkolaPositiv)) %>% 
  ggplot() +
  aes(x = value, y = PsykSomBesv) +
  geom_smooth(method = "gam") +
  facet_wrap(~ name)

psy1_f2g <- 
  gam(PsykSomBesv ~ Parenting + s(SkolaNegativ) + s(Community) + Utagerande + SkolaPositiv + f_utb + mobbad + bott, 
     data = df.f.gam)

glance(psy1_f2g)
glance(psy1_f2)
```

Ger inte jättemycket bättre AIC/BIC eller r2.

interaktion mellan f_utb och bott?

```{r}
psy1_f3 <- 
  lm(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb * bott + mobbad, 
     data = df.f.gam)

summary(psy1_f3)
```

nej.

#### pojkar

```{r}
# psy1_p2 <- 
#   lm_robust(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott, 
#             clusters = year,
#             data = df.p.gam)

# robust LM
psy1_p2 <- 
  MASS::rlm(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott + fr_aktiv, 
            data = df.p.gam)

check_collinearity(psy1_p2)
# get robust SE
# library(sandwich)
# library(lmtest) 
psy1_p2r <- coeftest(psy1_p2,
                          vcov = vcovCL,
                          #type = "HC3",
                          df = 9,  # clusters - 1, if needed
                          cluster = ~year)


modelsummary(psy1_p2r)
modelplot(psy1_p2r, coef_omit = "(Intercept)") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.5,0.5)) +
    #scale_y_discrete(labels = c("Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap")) +
    labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med riskfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall")

modelplot(psy1_p2,
          coef_omit = "Intercept|utb|9") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
    scale_y_discrete(labels = rev(c("Bott i Sverige hela mitt liv","Bott i Sverige 10 år eller mer","Utsatt för någon typ\nav mobbning","Positiv skolanknytning","Utagerande/\nnormbrytande beteende","Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
    labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       caption = "Ej statistiskt signifikanta variabler är bortplockade ur figuren.",
       x = "Regressionskoefficienter och 95% konfidensintervall") +
  scale_x_continuous(breaks = seq(-0.4,0.5,0.1))

#vip(psy1_p2)
modelplot(psy1_p2r, draw = F)

lm_items <-
  lm_items %>% 
  add_row(term = "bottHela mitt liv",
          desc = "Bott i Sverige hela livet")

tidy(psy1_p2r, conf.int = TRUE)%>% 
  mutate(across(where(is.numeric), ~ round(.x,3)),
         term = factor(term)) %>% 
  filter(!term == "(Intercept)",
         p.value < .05) %>%
  left_join(lm_items, by = "term") %>% 
  mutate(desc = fct_reorder(desc, estimate)) %>% 
  
  ggplot(aes(x = estimate, y = desc, color = ifelse(estimate > 0, "green","red"))) +
  geom_point(size = 4) +
  geom_segment(aes(x = conf.low, xend = conf.high)) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.4,0.5)) +
  #scale_y_discrete(labels = rev(c("Brukar delta i ledarledd\nfritidsaktivitet eller träning","Utsatt för någon typ\nav mobbning","Positiv skolanknytning","Utagerande/\nnormbrytande beteende","Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
  labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       x = "Regressionskoefficienter och 95% konfidensintervall",
       caption = str_wrap("Ej statistiskt signifikanta variabler är bortplockade ur figuren: Föräldrarnas utbildningsnivå", 66),
       y = "") +
  scale_x_continuous(breaks = seq(-0.4,0.5,0.1))

tidy(psy1_p2r) %>% 
  mutate(statistic = abs(statistic),
         term = factor(term),
         term = fct_reorder(term,statistic)) %>% 
  filter(statistic > 10) %>% 
  ggplot(aes(x = statistic, y = term)) +
  geom_col() +
  scale_y_discrete(labels = rev(c("Bristande föräldraskap","Utsatt för någon typ\nav mobbning","Negativ skolanknytning","Positiv skolanknytning","Utagerande/\nnormbrytande beteende"))) +
    labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       x = "T-värde från linjär regression",
       y = "")
```

Bristande föräldraskap framstår som den största riskfaktorn i denna modell.

```{r}
# jämförelse av klustrade SE under år
psy1_p2c <- 
  lm_robust(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott, 
            clusters = year,
            se_type = "CR2",
            data = df.p.gam)

psy1_p2 <- 
  lm(PsykSomBesv ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb * bott + mobbad, 
     data = df.p.gam)

glance(psy1_p2c)
glance(psy1_p2)


tidy(psy1_p2c) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3)))

tidy(psy1_p2) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3)))
```


Vi tittar närmare på den med matchning?

#### Matchning

```{r}
library(MatchIt)


```



#### Riskgrupp

Ta fram en variabel med enbart hög/låg risk för PSB, kör samma analys som ovan.

```{r}
df.f2 <- 
  df.f %>% 
  mutate(bott = factor(F5, levels = c("Mindre än 5 år","5-9 år", "10 år eller mer", "Hela mitt liv"))) %>%
  # rename(`Hur länge har du bott i Sverige?` = F5,
  #        `Vilken högsta utbildning har din mamma/pappa?` = f6ab,
  #        `Vad bor du i för typ av bostad?` = F7)
  mutate(mobbad = case_when(f60b == 1 ~ "Ja",
                            f60c == 1 ~ "Ja",
                            f60d == 1 ~ "Ja",
                            f60e == 1 ~ "Ja",
                            f60f == 1 ~ "Ja",
                            f60g == 1 ~ "Ja",
                            f60h == 1 ~ "Ja",
                            f60i == 1 ~ "Ja",
                            F63 == 1 ~ "Ja",
                            f60a == 1 ~ "Nej",
                            TRUE ~ NA
  )) %>%
  mutate(mobbad = factor(mobbad)) %>%
  #mutate(bott = case_when(F5 == "Hela mitt liv" | F5 == "10 år eller mer" ~ "10år+",
  #                        F5 == "5-9 år" | F5 == "Mindre än 5 år" ~ "0-9 år")) %>% 
  mutate(f_utb = factor(f6ab)) %>% 
  mutate(year = factor(År)) %>% 
  select(all_of(sthlm.index.all),f_utb,mobbad,bott,year,riskPsykSomBesv) %>%
  mutate(riskPSB = car::recode(riskPsykSomBesv,"'Något förhöjd risk'=0;'Låg risk'=0;'Förhöjd risk'=1", as.factor = FALSE)) %>% 
  #mutate(riskPSB = factor(riskPSB)) %>% #, levels = c(1,2), labels = c("Låg risk","Förhöjd risk"))) %>% 
  select(!Wellbeing) %>% 
  na.omit() %>% 
  as.data.frame()

df.f2 %>% 
  count(riskPSB)
```


```{r}
psy2_f_risk <- 
  glm(riskPSB ~ Parenting + SkolaNegativ + Community + Utagerande + SkolaPositiv + f_utb + mobbad + bott, 
      family = "binomial",
      data = df.f2)

modelplot(psy2_f_risk, exponentiate = TRUE, vcov = "HC3", coef_omit = "Intercept|utb|bott") +
  geom_vline(xintercept = 1, linetype = "dashed") +
  aes(color = ifelse(estimate < 1, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(0,2)) +
    scale_y_discrete(labels = rev(c("Ej mobbad","Positiv skolanknytning","Utagerande/normbrytande beteende","Otryggt närsamhälle","Negativ skolanknytning","Bristande föräldraskap"))) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med risk-/skyddsfaktorer",
       caption = "Ej statistiskt signifikanta variabler är bortplockade ur figuren.",
       x = "Regressionskoefficienter och 95% konfidensintervall")
  
```


```{r}
# relativ risk
avg_comparisons(
    psy2_f_risk,
    variables = "mobbad",
    comparison = "lnratioavg",
    transform = exp)
```


#### Mobbning uppdelad

```{r}
items_mobbning <- c("f60b", "f60c", "f60d", "f60e", "f60f", "f60g", "f60h", "f60i", "F63")
itemdesc_mobbning <- c("Jag har blivit hånad, förlöjligad, kallad öknamn eller blivit retad på ett obehagligt och sårande sätt", "Jag har blivit utfrusen av andra elever", "Jag har blivit slagen, sparkad, knuffad eller stängd inne", "Någon elev har spritt lögner eller falska rykten om mig och försökt få andra att tycka illa om mig", "Jag har blivit fråntagen pengar eller saker eller fått saker förstörda", "Jag har blivit hotad eller tvingad att göra saker som jag inte ville göra", "Lärare har psykat eller på annat sätt varit elaka mot mig", "Jag har mobbats på annat sätt.", "Har du blivit mobbad eller trakasserad via internet eller SMS/MMS det här läsåret?")

names(itemdesc_mobbning) <- items_mobbning
itemdesc_mobbning

i_mobb <- data.frame(itemnr = items_mobbning,
                     item = itemdesc_mobbning)

# df.f %>% 
#   select(all_of(items_mobbning)) %>% 
#   pivot_longer(everything()) %>% 
#   distinct(value)

f_mobb <- df.f %>% 
  select(all_of(items_mobbning),PsykSomBesv) %>% 
  lm(PsykSomBesv ~ .,
     data = .) 

check_collinearity(f_mobb)

f_mobb %>% 
  modelplot(vcov = "HC3", coef_omit = "(Intercept)", coef_map = itemdesc_mobbning) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  #aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.5,0.5)) +
  scale_y_discrete(labels = ~ str_wrap(.x, 32)) +
  labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med utsatthet för mobbning",
        x = "Regressionskoefficienter och 95% konfidensintervall")

tidy(f_mobb) %>% 
  mutate(statistic = abs(statistic),
         term = factor(term),
         term = fct_reorder(term,statistic)) %>% 
  filter(!term == "(Intercept)") %>% 
  arrange(desc(statistic)) %>% 
  head(5) %>% 
  left_join(i_mobb, by = join_by("term" == "itemnr")) %>% 
  mutate(item = fct_reorder(item, statistic)) %>% 
  ggplot(aes(x = statistic, y = item)) +
  geom_col() +
  scale_y_discrete(labels = ~ str_wrap(.x,28)) +
    labs(title = "Flickor åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med olika typer av mobbning",
       x = "T-värde från linjär regression",
       y = "")

p_mobb <- df.p %>% 
  select(all_of(items_mobbning),PsykSomBesv) %>% 
  lm(PsykSomBesv ~ .,
     data = .) 

tidy(p_mobb) %>% 
  mutate(statistic = abs(statistic),
         term = factor(term),
         term = fct_reorder(term,statistic)) %>% 
  filter(!term == "(Intercept)") %>% 
  arrange(desc(statistic)) %>% 
  head(5) %>% 
  left_join(i_mobb, by = join_by("term" == "itemnr")) %>% 
  mutate(item = fct_reorder(item, statistic)) %>% 
  ggplot(aes(x = statistic, y = item)) +
  geom_col() +
  scale_y_discrete(labels = ~ str_wrap(.x,28)) +
    labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med olika typer av mobbning",
       x = "T-värde från linjär regression",
       y = "")

p_mobb %>% 
  modelplot(vcov = "HC3", coef_omit = "(Intercept)", coef_map = itemdesc_mobbning) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  #aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  coord_cartesian(xlim = c(-0.5,0.5)) +
  scale_y_discrete(labels = ~ str_wrap(.x, 32)) +
  labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med utsatthet för mobbning",
        x = "Regressionskoefficienter och 95% konfidensintervall")
```

```{r}
df.p %>% 
  select(f60d,f60g,PsykSomBesv) %>% 
  lm(PsykSomBesv ~ .,
     data = .) %>% 
  modelplot(vcov = "HC3", coef_omit = "(Intercept)", coef_map = itemdesc_mobbning) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none") +
  #coord_cartesian(xlim = c(-0.5,0.5)) +
  scale_y_discrete(labels = ~ str_wrap(.x, 32)) +
  labs(title = "Pojkar åk 9: Psykiska/psykosomatiska besvär",
       subtitle = "Samband med utsatthet för mobbning",
        x = "Regressionskoefficienter och 95% konfidensintervall")
```




```{r}

```



```{r}
psy3_gam <- 
  df.fr %>% 
  gam(PsykSomBesv ~ s(Parenting) + s(SkolaNegativ) + s(Community), 
     data = .)

modelsummary(psy3_gam)
summary(psy3_gam)
plot_predictions(psy3_gam, "Parenting") + coord_cartesian(ylim = c(-1,2))
plot_predictions(psy3_gam, "SkolaNegativ") + coord_cartesian(ylim = c(-1,2))
plot_predictions(psy3_gam, "Community") + coord_cartesian(ylim = c(-1,2))

```

```{r}
psy4_gam <- 
  gam(PsykSomBesv ~ s(Parenting) + s(SkolaNegativ) + s(Community) + s(Utagerande) + s(SkolaPositiv) + f_utb + mobbad + bott, 
     data = df.f.gam)
glance(psy4_gam)

plot_predictions(psy4_gam, "Utagerande") + coord_cartesian(ylim = c(-1,2)) +
  scale_x_continuous(breaks = seq(-5,5,1))
plot_predictions(psy4_gam, "SkolaPositiv") + coord_cartesian(ylim = c(-1,2))+
  scale_x_continuous(breaks = seq(-5,5,1))

rslimits.prot

modelplot(psy4_gam, coef_omit = "(Intercept)") +
  geom_vline(xintercept = 0, linetype = "dashed") +
  aes(color = ifelse(estimate < 0, "red","green")) +
  guides(color = "none")


```

```{r}

```


#### Random forest regression



#### SEM

First CFA to review the measurement model fit.

```{r}
allItemInfo <- read_csv("../data/2024-01-23_allItemParams.csv")
items.psyk <- allItemInfo %>% 
  filter(Index == "PsykSomBesv") %>% 
  pull(itemnr)
items.parent <- allItemInfo %>% 
  filter(Index == "Parenting") %>% 
  pull(itemnr)
items.skolaneg <- allItemInfo %>% 
  filter(Index == "SkolaNegativ") %>% 
  pull(itemnr)

utfall_psy <- "PsykSomBesvCFA =~ F88 + F89 + F91 + F92 + F93 + F95 + F97 + F98 + F99
             ParentingCFA =~ F80 + f83b + f83d + f83e + f83f + F58
             SkolaNegativCFA =~ f54e +f54f+ f54i+ f54k + f54m +f54o +f54q
              "

mm1 <- cfa(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

# create table with model fit metrics
# define fit metrics of interest
fit_metrics_robust <- c("chisq.scaled", "df", "pvalue.scaled", 
                         "cfi.scaled", "tli.scaled", "rmsea.scaled", "srmr")
fitmeasures(mm1, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
```

```{r}
lavaanPlot(model = mm1, 
           coefs = T, stand = T, covs = T,
           node_options = list(fontname = "Helvetica"), 
           edge_options = list(color = "grey"),
           graph_options = list(rankdir = "LR"))
```

SEM

```{r}
utfall_psy <- "PsykSomBesvCFA =~ F88 + F89 + F91 + F92 + F93 + F95 + F97 + F98 + F99
             ParentingCFA =~ F80 + f83b + f83d + f83e + f83f + F58
             SkolaNegativCFA =~ f54e +f54f+ f54i+ f54k + f54m +f54o +f54q
             PsykSomBesvCFA ~ a*ParentingCFA + b*SkolaNegativCFA
              "

psy_sem1 <- sem(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

fitmeasures(psy_sem1, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')

lavResiduals(psy_sem1)

lavaanPlot(model = psy_sem1,
           coefs = T, stand = T, covs = T,
           node_options = list(fontname = "Helvetica"), 
           edge_options = list(color = "grey"),
           graph_options = list(rankdir = "LR"))

library(semPlot)
semPaths(object = psy_sem1,
         whatLabels="est")

psy_sem1_out <- summary(psy_sem1, standardized = TRUE)

psy_sem1_out$pe %>% 
  filter(op == "~") %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  kbl_rise()
```

check residuals for SEM

```{r}
# https://github.com/yrosseel/lavaan/issues/269
lavResidualsY <- function(object,
                          ynames = lavNames(object, "ov.nox"),
                          xnames = lavNames(object, "ov.x")){
  pred <- lavPredictY(object,
                      ynames = ynames,
                      xnames = xnames) |> 
    as.data.frame()
  
  d <- inspect(object, "data") |> 
    as.data.frame()

  r <- lapply(names(pred), function(x){
    pred[[x]] - d[[x]]
  })

  res <- do.call(cbind, r) |> 
    as.data.frame()
  names(res) <- names(pred)
  
  res
}

lavResidualsY(psy_sem1,
              ynames = c("F88","F89","F91","F92","F93","F95","F97","F98","F99"),
              xnames = c("F80","f83b","f83d","f83e","f83f","F58"))

# "f54e","f54f","f54i","f54k","f54m","f54o","f54q"

```

no support for DWLS estimator output in lavPredictY. Let's pretend our variables are continuous.

```{r}
psy_sem1c <- sem(
  model = utfall_psy,
  data = df.f,
  rotation = "oblimin",
  estimator = "ML",
)

summary(psy_sem1c, fit.measures = TRUE, standardized = TRUE)

psy_sem1c_resids <- lavResidualsY(psy_sem1c,
              ynames = c("F88","F89","F91","F92","F93","F95","F97","F98","F99"),
              xnames = c("F80","f83b","f83d","f83e","f83f","F58"))

glimpse(psy_sem1c_resids)

mvnormtest::mshapiro.test(t(sample(psy_sem1c_resids, 100, replace = TRUE)))

```

SEM with fixed factor loadings @1

```{r}
utfall_psy2 <- "PsykSomBesvCFA =~ 1*F88 + 1*F89 + 1*F91 + 1*F92 + 1*F93 + 1*F95 + 1*F97 + 1*F98 + 1*F99
             ParentingCFA =~ 1*F80 + 1*f83b + 1*f83d + 1*f83e + 1*f83f + 1*F58
             SkolaNegativCFA =~ 1*f54e + 1*f54f + 1*f54i + 1*f54k + 1*f54m + 1*f54o + 1*f54q
             PsykSomBesvCFA ~ a*ParentingCFA + b*SkolaNegativCFA
              "

psy_sem2 <- sem(
  model = utfall_psy2,
  data = df.f,
  rotation = "oblimin",
  estimator = "WLSMV",
  ordered = TRUE
)

fitmeasures(psy_sem2, fit_metrics_robust) %>% 
  rbind() %>% 
  as.data.frame() %>% 
  mutate(across(where(is.numeric),~ round(.x, 3))) %>%
  rename(Chi2 = chisq.scaled,
         p = pvalue.scaled,
         CFI = cfi.scaled,
         TLI = tli.scaled,
         RMSEA = rmsea.scaled,
         SRMR = srmr) %>% 
  formattable(.,
              table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
```


##### Riskgrupp

```{r}
psy2_f <- 
  df.f %>% 
  lm(PsykSomBesv ~ riskParenting + riskSkolaNegativ + riskCommunity, 
     data = .)
#check_model(psy2_f)
check_normality(psy2_f)
avg_slopes(psy2_f)
```

```{r}
plot_predictions(psy2_f, "riskParenting") +
  coord_cartesian(ylim = c(-2, 2))
plot_predictions(psy2_f, "riskSkolaNegativ") +
  coord_cartesian(ylim = c(-2, 2))
plot_predictions(psy2_f, "riskCommunity") +
  coord_cartesian(ylim = c(-2, 2))
```


## Kriminalitet

Det finns 19 frågor som handlar om självrapportering av att ha begått olika typer av brott.

#### Antal brott
```{r}
items.brott <- df %>% 
  select(starts_with("f75")) %>% 
  names()

itemlabels_brott <- read_excel("10_Brott/BrottItemlabels.xls")

itemlabels_brott %>% 
  filter(itemnr %in% items.brott) %>%
  kable() 
```

Summerar vi dem per respondent ser distributionen av individer som rapporterar att ha begått ett visst antal brott vid ett och samma mättillfälle enligt nedan.

```{r}
df <- df %>% 
  mutate(AntalBrott = rowSums(across(all_of(items.brott)), na.rm = T))

df %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_bar(fill = RISEprimGreen)

df %>% 
  group_by(År) %>% 
  count(AntalBrott) %>% 
  ungroup() %>% 
  filter(AntalBrott < 8) %>% 
  mutate(AntalBrott = factor(AntalBrott)) %>% 
  ggplot(aes(x = År, y = n, group = AntalBrott, color = AntalBrott)) +
  geom_point() +
  geom_line() +
  scale_color_viridis_d(direction = -1) +
  scale_x_continuous(breaks = årtal)

df %>% 
  ggplot(aes(x = AntalBrott, fill = Kön)) +
  geom_bar(alpha = 0.8, position = "fill") +
  scale_fill_manual(values = c(RISEprimGreen, "orange")) +
  labs(title = "Antal brott fördelat på kön",
       x = "Antal brott",
       y = "Andel")
```

Flickor begår något oftare 1-2 brott än pojkar, men sedan vänder trenden.

Vilken typ av brott är vanligare bland pojkar respektive flickor?

```{r}
brott.kön <- 
  df %>% 
  select(Kön, all_of(items.brott)) %>% 
  glm(Kön ~ ., data = ., family = binomial(link = "logit"))

#modelsummary(brott.kön, exponentiate = TRUE)
library(broom.mixed)
tidy(brott.kön) %>% 
  filter(!p.value > 0.05) %>% 
  arrange(desc(estimate)) %>% 
  left_join(itemlabels_brott, by = c("term" = "itemnr")) %>% 
  mutate_if(is.numeric, round, 2) %>%
  kable()
```

Brott ovanför Intercept-raden är vanligare bland pojkar. Desto längre från Intercept, desto större skillnad mellan pojkars och flickors sannolikhet att begå brott av den typen. Brott som ej har en statistiskt signifikant skillnad är inte med i tabellen. Men p.g.a. vårt stora sampel är statistisk signifikans inte nödvändigtvis en indikator på att det är stor skillnad, här gäller det snarare att titta på "estimate" i tabellen.

```{r}
brottlabels <- itemlabels_brott$item[c(1:19)] %>% 
  rev()
library(parameters)

parameters(brott.kön, ci_method="wald") %>% 
  plot() +
  scale_color_manual(values = c("orange", RISEprimGreen)) +
  labs(title = str_wrap("Skillnad mellan pojkar och flickor i sannolikhet att självrapportera olika typer av brott"),
       subtitle = str_wrap("Blågröna prickar indikerar brott med högre sannolikhet att begås av flickor, om linjen för konfidensintervallet inte korsar noll-strecket. Längre avstånd från 0 = större skillnad mellan könen."),
       #x = "",
       y = "Brottstyp") +
  theme_rise() +
  guides(color = "none") +
  scale_y_discrete(labels = str_wrap(paste0(brottlabels), width = 36))
```

```{r}
brott_items <- itemlabels_brott$item[c(1:19)]
names(brott_items) <- itemlabels_brott$itemnr[c(1:19)]

modelplot(brott.kön, exponentiate = TRUE, vcov = "HC3", coef_omit = "Intercept", coef_map = brott_items) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  aes(color = ifelse(estimate < 1, "orange", RISEprimGreen)) +
  guides(color = "none") +
  scale_y_discrete(labels = ~ str_wrap(.x, width = 36)) +
    labs(title = str_wrap("Skillnad mellan pojkar och flickor i sannolikhet att självrapportera olika typer av brott"),
       subtitle = str_wrap("Blågröna prickar indikerar brott med högre sannolikhet att begås av flickor, om linjen för konfidensintervallet inte korsar vertikala strecket. Längre avstånd från 1.0 = större skillnad mellan könen."),
       x = "",
       y = "")

```


Vi kan också titta på hur stor andel av respondenterna som rapporterar att ha begått ett visst antal brott vid ett och samma mättillfälle.

```{r}
df %>% 
  count(AntalBrott) %>%
  mutate(Andel = 100*n/sum(n)) %>%
  ggplot(aes(y = Andel, x = AntalBrott)) +
  geom_col(fill = RISEprimGreen) +
  geom_text(aes(label = paste0(round(Andel, 1), "%")), 
            vjust = -0.5, size = 3) +
  labs(x = "Antal självrapporterade brott som begåtts")

df %>% 
  count(AntalBrott) %>%
  mutate(Andel = 100*n/sum(n)) %>%
  slice(1:4) %>% 
  summarise(Andel = sum(Andel) %>% round(1)) %>% 
  kable()
```

83.1 % av respondenterna rapporterar max 3 brott, varav 38.1 % rapporterar 0 brott.

Vilka brott som självrapporteras oftast?

```{r}
df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  arrange(desc(n)) %>% 
  mutate(Andel = 100*n/sum(n)) %>%
  ggplot(aes(y = Andel, x = reorder(item, n))) +
  geom_col(fill = RISEprimGreen) +
  geom_text(aes(label = paste0(round(Andel, 1), "%")), 
            hjust = -0.3, size = 4) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8)) +
  labs(x = "Brott", y = "Andel (%)",
       title = "Vanligast självrapporterade begångna brott") 

df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  arrange(desc(n)) %>% 
  slice(1:5) %>% 
  left_join(itemlabels_brott, by = c("item" = "itemnr")) %>%
  select(!n) %>% 
  kable()

df %>% 
  select(all_of(items.brott)) %>% 
  pivot_longer(everything(), names_to = "item", values_to = "svar") %>% 
  filter(svar == 1) %>% 
  count(item) %>% 
  mutate(Andel = 100*n/sum(n)) %>%
  arrange(desc(n)) %>% 
  slice(1:3) %>% 
  summarise(Summa = sum(Andel))
```

De tre vanligaste brotten står för 49% av alla brott som självrapporteras. 

Vilka brott rapporteras när man rapporterar fler än 0?

```{r}
df %>% 
  filter(AntalBrott > 0) %>% 
  select(all_of(items.brott),AntalBrott) %>% 
  pivot_longer(all_of(items.brott), names_to = "item", values_to = "svar") %>% 

  ggplot(aes(y = svar, x = AntalBrott, fill = item)) +
  geom_col() +
  scale_fill_viridis_d()
  
```

Hur många självrapporterar något av de tre vanligast förekommande (75p tjuvåkt tunnelbana, 75a snattat, 75i tagit pengar hemma)?


```{r}
df %>% 
  mutate(brott3 = case_when(f75p == 1 | f75a == 1 | f75i == 1 ~ "Något av de tre vanligaste brotten", 
                            AntalBrott == 0 ~ "Inga brott", 
                            TRUE ~ "Övriga")) %>%
  count(brott3) %>%
  mutate(Andel = round(100*n/sum(n),2)) %>% 
  kable()

```
ca 60% självrapporterar något av de tre vanligaste brotten.

### Statistisk modell för pojkar

Vi tittar först på Antal Brott som utfall. Distributionen av data följer en negativ exponentiell kurva, vilket är vanligt för räknevariabler. 

```{r}
mean(df$AntalBrott, na.rm = TRUE)
var(df$AntalBrott, na.rm = TRUE)
```

Vi ser också att variansen är större än medelvärdet ("overdispersion"), vilket är en indikation på att en Poisson-modell inte är lämplig. Därför används en negativ binomial regressionsmodell som utgångspunkt. Det är också sannolikt att en s.k. hurdle-modell fungerar väl med denna typ av data ("zero-inflated"), så vi jämför båda.

#### Prediktorer

Vi behöver reda ut vilka prediktorer som är viktiga att ha med, och hur deras inbördes relationer ser ut.

```{r}
# betyg/skolresultat
df <- df %>% 
  mutate(across(starts_with("F65"), ~ car::recode(.x,"'Streck' = 0;
                                                  'F' = 1;
                                                  'E' = 2;
                                                  'D' = 3;
                                                  'C' = 4;
                                                  'B' = 5;
                                                  'A' = 6;
                                                  ",as.factor=FALSE),
         .names = "{col}_num"))

df <- df %>% 
  mutate(betyg = rowMeans(.[,c("F65a_num","F65b_num","F65c_num")], na.rm = FALSE))

# betyg som dikotom variabel, där godkända betyg är A-E och underkända är F och streck
# ej godkänd i något ämne kodas som ej godkänd
df <- df %>% 
  mutate(betyg_dik = case_when(F65a_num < 2 | F65b_num < 2 | F65c_num < 2 ~ "Ej godkänd", 
                                   TRUE ~ "Godkänd"))

# föräldrarnas utbildningsnivå, högsta av mammas och pappas
df <- df %>% 
  rename(ParentEdu = f6ab)
```

Fördelningar av betyg och föräldrarnas utbildningsnivå:

```{r}
df %>% 
  ggplot(aes(x = betyg)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") 

df %>%
  ggplot(aes(x = ParentEdu)) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(x = "Föräldrarnas utbildningsnivå", y = "Antal")

df %>% 
  ggplot(aes(x = ParentEdu, y = betyg, color = Kön)) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  geom_boxplot(alpha = 0.7, notch = TRUE) +
  theme(axis.text.x = element_text(angle = 45)) +
  labs(x = "Föräldrarnas utbildningsnivå", y = "Självrapporterade betyg i kärnämnen") +
  scale_color_gender() +
  scale_fill_gender()

# betyg dikotomiserad
df %>% 
  ggplot(aes(x = betyg_dik, fill = Kön)) +
  geom_bar(position = "dodge", color = "black") +
  scale_fill_gender()

# betyd dikotomiserad fördelad på föräldrarnas utbildningsnivå
df %>% 
  ggplot(aes(x = betyg_dik, fill = Kön)) +
  geom_bar(position = "dodge", color = "black") +
  scale_fill_gender() +
  labs(x = "", y = "Antal") +
  theme(axis.text.x = element_text(angle = 45)) +
  facet_wrap(~ParentEdu)

```

##### Risk för ej godkända betyg

borde läggas någon annanstans, men ovan här är data väl illustrerat

```{r}
betyg_f <- 
  df %>% 
  mutate(betyg_dik = car::recode(betyg_dik,"'Ej godkänd'=0;'Godkänd'=1")) %>% 
  filter(Kön == "Flicka") %>% 
  glm(betyg_dik ~ ParentEdu,
      data = .,
      family = "binomial")

betyg_p <- 
  df %>% 
  mutate(betyg_dik = car::recode(betyg_dik,"'Ej godkänd'=0;'Godkänd'=1")) %>% 
  filter(Kön == "Pojke") %>% 
  glm(betyg_dik ~ ParentEdu,
      data = .,
      family = "binomial")

# risk ratio
avg_comparisons(
    betyg_f,
    variables = "ParentEdu",
    comparison = "lnratioavg",
    transform = exp)

# risk ratio
avg_comparisons(
    betyg_p,
    variables = "ParentEdu",
    comparison = "lnratioavg",
    transform = exp)

```

Större risk ratio för pojkar att ej få godkända betyg i grundämnen i grundskolan om föräldrarna är lågutbildade.

lägg till bristande föräldraskap som prediktor

```{r}
betyg_f2 <- 
  df %>% 
  mutate(betyg_dik = car::recode(betyg_dik,"'Ej godkänd'=0;'Godkänd'=1")) %>% 
  filter(Kön == "Flicka") %>% 
  glm(betyg_dik ~ ParentEdu + Parenting,
      data = .,
      family = "binomial")

betyg_p2 <- 
  df %>% 
  mutate(betyg_dik = car::recode(betyg_dik,"'Ej godkänd'=0;'Godkänd'=1")) %>% 
  filter(Kön == "Pojke") %>% 
  glm(betyg_dik ~ ParentEdu + Parenting,
      data = .,
      family = "binomial")

avg_comparisons(
    betyg_f2,
    variables = "ParentEdu",
    comparison = "lnratioavg",
    transform = exp)

avg_comparisons(
    betyg_p2,
    variables = "ParentEdu",
    comparison = "lnratioavg",
    transform = exp)

modelplot(list("Pojke" = betyg_p2, 
               "Flicka" = betyg_f2),
          coef_omit = 'Interc', exponentiate = FALSE,
          title = "Föräldrarnas utbildningsnivå och bristande föräldraskap") +
  scale_color_gender() +
  coord_cartesian(xlim = c(-0.5,2.5))

modelsummary(list("Pojke" = betyg_p2, 
               "Flicka" = betyg_f2))

```

Bristande föräldraskap har liten betydelse för sannolikheten att gå ut grundskolan med godkända betyg.

Vi tittar på sambandet mellan föräldrarnas utbildningsnivå och Bristande föräldraskap. En negativ koefficient innebär att utbildningsnivån sänker riskfaktorn jämfört med den lägsta utbildningsnivån (enbart grundskola).

```{r}
# draw a box+jitter plot of Parenting by ParentEdu
df2 <- df %>% 
  filter(Kön %in% c("Pojke","Flicka")) %>% 
  drop_na(Utagerande, Parenting, ParentEdu)

ggplot(df2, aes(x = ParentEdu, y = Parenting, color = Kön, fill = Kön)) +
  geom_jitter(width = 0.2, alpha = 0.1) +
  geom_boxplot(alpha = 0.7, notch = TRUE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_gender() +
  scale_fill_gender()
```

##### Linear regression
```{r}
pedu_p <- lm(Parenting ~ ParentEdu, data = df2 %>% filter(Kön == "Pojke"))
pedu_f <- lm(Parenting ~ ParentEdu, data = df2 %>% filter(Kön == "Flicka"))

modelplot(list("Pojke" = pedu_p, 
               "Flicka" = pedu_f),
          coef_omit = 'Interc',
          title = "Föräldrarnas utbildningsnivå och bristande föräldraskap") +
  scale_color_gender() +
  coord_cartesian(xlim = c(-0.5,0.5))

modelsummary(list("Pojke" = pedu_p, 
                  "Flicka" = pedu_f),
             title = "Föräldrarnas utbildningsnivå och bristande föräldraskap", 
             stars = TRUE, statistic = 'conf.int')
```



##### Noteringar

testa att ta bort respondenter med hög person infitZ
quantreg median regression
se om det går att göra en GLM latent regression och/eller en brms-irt-modell?


Sedan effekter av parenting och utbildningsnivå på utagerande (pojke som exempel)

```{r}
#parenting_p0rq <- rq(Utagerande ~ Parenting, data = df2 %>% filter(Kön == "Pojke"))
library(gvlma)

parenting_p0 <- lm(Utagerande ~ Parenting, data = df2 %>% filter(Kön == "Pojke"))
parenting_p1 <- lm(Utagerande ~ ParentEdu, data = df2 %>% filter(Kön == "Pojke"))
parenting_p2 <- lm(Utagerande ~ Parenting + ParentEdu, data = df2 %>% filter(Kön == "Pojke"))
parenting_p3 <- lm(Utagerande ~ Parenting * ParentEdu, data = df2 %>% filter(Kön == "Pojke"))

modelplot(list("Parenting" = parenting_p0, 
               "ParentEdu" = parenting_p1,
               "Parenting + ParentEdu" = parenting_p2,
               "Parenting * ParentEdu" = parenting_p3),
          title = "Parenting/parentEdu och utagerande")

modelsummary(list("Parenting" = parenting_p0, 
                  "ParentEdu" = parenting_p0,
                  "Parenting + ParentEdu" = parenting_p2,
                  "Parenting * ParentEdu" = parenting_p3),
             title = "Parenting/parentEdu och utagerande", 
             stars = TRUE)

gvlma(parenting_p0)
# scatter plot of residuals
plot(parenting_p0, which = 1)
# qq plot of residuals
plot(parenting_p0, which = 2)
# Utagerande/parenting scatter plot
df2 %>% 
  ggplot(aes(x = Parenting, y = Utagerande, color = Kön)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  theme_minimal() +
  scale_color_gender()

hist(residuals(parenting_p0))
hist(df2$Utagerande,breaks = 50)
hist(df2$Parenting, breaks = 50)

gvlma(parenting_p1)

```



```{r}
#| eval: false
pedu_ipw <- glm(ParentEdu ~ Parenting, data = df %>% filter(Kön == "Pojke") %>% drop_na(ParentEdu, Parenting), 
                        family = binomial(link = "logit"))

pedu_propensities <- augment(pedu_ipw, type.predict = "response") %>%
  mutate(p_edu = .fitted)

# formula only works for binary ParentEdu variable
# pedu_propensities %>% 
#   mutate(w_ate = (ParentEdu / p_edu) + ((1 - ParentEdu) / (1 - p_edu)),
#          w_ato = (1 - p_edu) * ParentEdu + p_edu * (1 - ParentEdu))

# let's try matching instead
library(MatchIt)  # For matching stuff

matched <- matchit(ParentEdu ~ Parenting, 
                   data = df %>% filter(Kön == "Pojke") %>% drop_na(ParentEdu, Parenting),
                   method = "full", distance = "mahalanobis", replace = TRUE)

```

#### DAG

Vi behöver en idé om vilka variabler som ska ingå i den statistiska modellen som prediktorer och kovariat. Därför ritar vi en kausal modell (DAG) för att visualisera de antagna sambanden mellan variablerna. 

```{r}
# https://evalf20.classes.andrewheiss.com/example/dags/#plot-dag-from-dagitty-net-with-ggdag
library(ggdag) 
library(dagitty) 

# Create DAG
simple_dag <- dagify(
  AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community,
  Utagerande ~ Parenting,
  exposure = "Utagerande",
  outcome = "AntalBrott",
  labels = c(
    AntalBrott = "Antal brott",
    Utagerande = "Utåtagerande beteende",
    Parenting = "Bristande föräldraskap",
    SkolaNegativ = "Vantrivsel i skolan",
    Community = "Dålig relation till närsamhället")
)

# Adding a theme_dag() layer to the plot makes it have a white background with no axis labels
ggdag(simple_dag,
      use_labels = "label",
      text = FALSE) +
  theme_dag()
```

```{r}
impliedConditionalIndependencies(simple_dag)
# test independence
cor(df$Community, df$Parenting, use = "complete.obs")
cor(df$Community, df$SkolaNegativ, use = "complete.obs")
cor(df$Community, df$Utagerande, use = "complete.obs")
cor(df$Parenting, df$SkolaNegativ, use = "complete.obs")
cor(df$SkolaNegativ, df$Utagerande, use = "complete.obs")
adjustmentSets(simple_dag)
paths(simple_dag)
```


```{r}
dag2 <- dagify(
  AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community,
  Utagerande ~ Parenting,
  Parenting ~ Community, 
  SkolaNegativ ~ Community,
  Parenting ~ SkolaNegativ,
  SkolaNegativ ~ Parenting,
  SkolaNegativ ~ Utagerande,
  Parenting ~ Utagerande,
  
  exposure = "Utagerande",
  outcome = "AntalBrott",
  labels = c(
    AntalBrott = "Antal brott",
    Utagerande = "Utåtagerande beteende",
    Parenting = "Bristande föräldraskap",
    SkolaNegativ = "Vantrivsel i skolan",
    Community = "Dålig relation till närsamhället")
)
ggdag(dag2,
      use_labels = "label",
      text = FALSE) +
  theme_dag()

impliedConditionalIndependencies(dag2)
adjustmentSets(dag2)
```

Model test

```{r}


brott.nb0 <- pscl::hurdle(AntalBrott ~ (Utagerande + Parenting + ParentEdu)^3, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
modelsummary(brott.nb0)

p1 <- plot_predictions(brott.nb0, cond = "Utagerande", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p2 <- plot_predictions(brott.nb0, cond = "Parenting", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p3 <- plot_predictions(brott.nb0, cond = "ParentEdu", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))

p1 / p2 + p3 
```



#### Negative binomial regression

```{r}
brott.nb <- glm.nb(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Pojke"))
modelsummary(brott.nb)

p1 <- plot_predictions(brott.nb, cond = "Utagerande", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p2 <- plot_predictions(brott.nb, cond = "Parenting", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p3 <- plot_predictions(brott.nb, cond = "SkolaNegativ", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p4 <- plot_predictions(brott.nb, cond = "Community", vcov = "HC3") +
  coord_cartesian(ylim = c(0, 20))
p1 + p2 + p3 + p4 
```

Var passeras antal brott = 3 på de två prediktorerna som visar starkast samband, enligt modellen? OBS att det enbart är pojkar i modellen.

```{r}
predictions(brott.nb, newdata = datagrid(Utagerande = seq(0.5,1.2, 0.05)), vcov = "HC3")
predictions(brott.nb, newdata = datagrid(Parenting = seq(1,1.5, 0.05)), vcov = "HC3")
```

Enligt modellen är det vid Utagerande 0.75 (även nedre konfidensintervallet går över 3) och Parenting = 1.3 (eller 1.5 där nedre konfidensintervall överstiger 3) som AntalBrott överstiger 3.

```{r}
rslimits %>% 
  select(Utagerande, Parenting) %>%
  kbl_rise()

```

Sett till brott som utfall ser vi alltså vissa skillnader mot de distributionsbaserade gränsvärden som hittills använts, om vi tänker att det är rimligt att se 3 brott som en gräns. 


#### Hurdle negative binomial
```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
modelsummary(brott.hrd)
```

```{r}
p1 <- plot_predictions(brott.hrd, cond = "Utagerande") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p2 <- plot_predictions(brott.hrd, cond = "Parenting") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p3 <- plot_predictions(brott.hrd, cond = "SkolaNegativ") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p4 <- plot_predictions(brott.hrd, cond = "Community") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p1 + p2 + p3 + p4 +
  plot_annotation(title = "Riskfaktorer för självrapporterat antal begångna brott - Pojkar",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(0.6,1, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(1,1.5, 0.02)))

predictions(brott.hrd, newdata = datagrid(Utagerande = seq(0.5,1.5, 0.01))) %>% 
  ggplot(aes(x = Utagerande, y = estimate)) +
  geom_line() +
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.2) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(x = "Utagerande", y = "Antal brott")

```

Hurdle-modellen ger liknande resultat, Utagerande = 0.7 (CI lower = 0.74) och Parenting ca 1.2 (CI lower = 1.34). 

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(1.1, 1.36, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(2.3,2.7, 0.02)))
```

För antal brott = 4 blir 

- Utagerande = 1.26 (CI lower 1.32)
- Parenting = 2.38 (CI lower 2.66)
```{r}
AIC(brott.nb,brott.hrd)
```

Hurdle-modellen verkar passa data något bättre. Vi såg i modelsummary-outputen tidigare även att RMSE var något lägre för Hurdle-modellen. 


### Statistisk modell för flickor

#### Hurdle negative binomial

```{r}
df %>% 
  filter(Kön == "Flicka") %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_histogram(binwidth = 1)
```


```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community, 
            data = df %>% filter(Kön == "Flicka"),
            dist = "negbin")
modelsummary(brott.hrd)

```

```{r}
p1 <- plot_predictions(brott.hrd, cond = "Utagerande") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p2 <- plot_predictions(brott.hrd, cond = "Parenting") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p3 <- plot_predictions(brott.hrd, cond = "SkolaNegativ") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p4 <- plot_predictions(brott.hrd, cond = "Community") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed")
p1 + p2 + p3 + p4 +
  plot_annotation(title = "Riskfaktorer för självrapporterat antal begångna brott - Flickor",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
predictions(brott.hrd, newdata = datagrid(Utagerande = seq(1,1.5, 0.02)))
predictions(brott.hrd, newdata = datagrid(Parenting = seq(2,4, 0.1)))
```

Gränsvärden för flickor:

- Utagerande = 1.12 och CI lower 1.16
- Parenting = når ej upp till antal brott = 3 någonstans längs riskfaktorns skala.

#### Skolresultat som riskfaktor

```{r}
hist(df$Skola3betygMedel, breaks = 25)
```
##### Kontinuerlig betygsvariabel

```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community + Skola3betygMedel, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
plot_predictions(brott.hrd, cond = "Skola3betygMedel") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(title = "Riskfaktorer för självrapporterat antal begångna brott - Pojkar",
       subtitle = "Hurdle negative binomial regression model")
```

##### Dikotomiserad betygsvariabel
```{r}

brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community + betyg_dik, 
            data = df %>% filter(Kön == "Pojke"),
            dist = "negbin")
plot_predictions(brott.hrd, cond = "betyg_dik") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(title = "Riskfaktorer för självrapporterat antal begångna brott - Pojkar",
       subtitle = "Hurdle negative binomial regression model")
```

```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Parenting + SkolaNegativ + Community + Skola3betygMedel, 
            data = df %>% filter(Kön == "Flicka"),
            dist = "negbin")
plot_predictions(brott.hrd, cond = "Skola3betygMedel") +
  coord_cartesian(ylim = c(0, 20)) +
  geom_hline(yintercept = 3, linetype = "dashed") +
  labs(title = "Riskfaktorer för självrapporterat antal begångna brott - Flickor",
       subtitle = "Hurdle negative binomial regression model")
```

Noteringar:

- lägg till utbildningsnivå föräldrar (sammanslagen för båda, där högsta räknas).
- interaktionseffekt Parenting/utbildningsnivå?
- lägg till klustring för år och kommun?
- klustring skola/vantrivsel?


## Substansbruk






## Stabilitet i sambandsmodeller

Data splittas på årsbasis för att undersöka om sambanden är likartade över tid (2006-2020).

## Korrelationsmatris

Alla variabler utom välbefinnande. Enbart utifrån år 2020.

```{r}
#| fig-width: 9
#| fig-height: 6

df %>% 
  filter(ar == 2020) %>% 
  select(all_of(sthlm.index),Kön) %>% 
  ggpairs(aes(color = Kön), alpha = 0.8) +
  scale_color_manual(values = RISEpalette1[c(2,5)],
                     aesthetics = c("color", "fill"))
```

### Värden från alla år
```{r}
corrModels <- df2 %>%
  select(all_of(sthlm.index.all),ar) %>% 
  split(.$ar) %>%
  map(~ cor(., use = "pairwise.complete.obs"))
# 
# df2 %>% 
#   select(all_of(sthlm.index.all)) %>% 
#   cor(. , use = "pairwise.complete.obs")

corrTable <- corrModels %>% 
  map(as_tibble) %>% 
  bind_rows() %>% 
  add_column(År = rep(årtal, each = 8)) %>% 
  select(!ar) %>% 
  na.omit()
```


## Utagerande och andra variabler

### Utagerande och Parenting

```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  select(Utagerande, Parenting, Kön) %>% 
  ggplot(aes(x = Parenting, y = Utagerande, color = Kön)) +
  geom_point2(alpha = 0.5, size = 2.2) +
  geom_smooth(linewidth = 1.6) +
  scale_color_manual(values = RISEpalette1[c(1,5)],
                     aesthetics = c("color", "fill"))
```

### LMM Utagerande 1
```{r}
models1 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + Kön, data = .))


# models1 %>%
#   map(summary) %>%
#   map("coefficients") %>%
#   map_df(as_tibble)

compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

compEstimates(models1,3)

sumEstimates <- function(m) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  group_by(term) %>%
  summarise(
    Medel = mean(estimate),
    SD = sd(estimate),
    Max = max(estimate),
    Min = min(estimate),
    MaxDiff = Max - Min
  ) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}

sumEstimates(models1)

# compare r-squared across years
compRsq <- function(m) {
  m %>% 
  map(summary) %>% 
  map_dbl("r.squared") %>% 
  as.data.frame() %>%
  rownames_to_column() %>% 
  setNames(c("År","R-squared")) %>% 
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}
compRsq(models1)

# compare RMSE across years
compRMSE <- function(m) {
  m %>% 
  #map(summary) %>% 
  #map_dbl("sigma") %>% 
  map_dbl(~sqrt(mean(residuals(.x)^2))) %>% 
  as.data.frame() %>%
  rownames_to_column() %>% 
  setNames(c("År","RMSE")) %>% 
  mutate(across(where(is.numeric), round, 3)) %>%
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
  )
}
compRMSE(models1)

```

#### Random intercept kön

```{r}
models1b <- df2 %>% 
  split(.$ar) %>%
  map(~ lmer(Utagerande ~ Parenting + (1|Kön), data = .))
library(broom.mixed)
models1b %>% 
  map(broom.mixed::tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 4), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  kbl_rise()

lmer1 <- df2 %>% 
  filter(ar == 2020) %>%
  lmer(Utagerande ~ Parenting + (1|Kön), data = .)
lm1k <- df2 %>% 
  filter(ar == 2020) %>%
  lm(Utagerande ~ Parenting + Kön, data = .)
AIC(lmer1,lm1k)
```


#### Uppdelat på kön

```{r}

modelsP <- df2 %>%
  filter(Kön == "Pojke") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

modelsF <- df2 %>%
  filter(Kön == "Flicka") %>% 
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting, data = .))

compEstimatesG <- function(m,n,filename) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write_csv(.,filename) 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}
compEstimatesG(models1,3,"Samband/compEstimates.csv")
compEstimatesG(modelsP,2,"Samband/compEstimatesPojkar.csv")
compEstimatesG(modelsF,2,"Samband/compEstimatesFlickor.csv")

```
#### Tabell
```{r}
allEstimates <- read_csv("Samband/compEstimates.csv") %>% 
  select(!ends_with("KönPojke")) %>% 
  add_column(Respondent = 'Alla')
fEstimates <- read_csv("Samband/compEstimatesFlickor.csv") %>% 
  add_column(Respondent = 'Flickor')
pEstimates <- read_csv("Samband/compEstimatesPojkar.csv") %>% 
  add_column(Respondent = 'Pojkar')

aEstimates <- rbind(allEstimates,fEstimates,pEstimates) %>% 
  janitor::clean_names(case = "snake")

aEstimates %>% 
  group_by(respondent) %>% 
  summarise(medel_intercept = mean(estimate_intercept),
            sd_intercept = sd(estimate_intercept),
            max_intercept = max(estimate_intercept),
            min_intercept = min(estimate_intercept),
            medel_parenting = mean(estimate_parenting),
            sd_parenting = sd(estimate_parenting),
            max_parenting = max(estimate_parenting),
            min_parenting = min(estimate_parenting)
            ) %>% 
  mutate(across(where(is.numeric), ~ round(.x,3))) %>% 
  kbl_rise()

```

#### Tabell standardiserad
```{r}
library(datawizard)
compEstimates <- function(m,n) {
  m %>%
  map(tidy) %>% # makes multiple tibbles
  bind_rows() %>% # stack them
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = n), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  #  write.csv(.,"compEstimates.csv") 
  formattable(.,
    table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')
}

models1 %>% 
  map(datawizard::standardize) %>% 
  map(tidy) %>% 
  bind_rows() %>% 
  select(term, estimate, std.error) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  add_column(Year = rep(årtal, each = 3), .before = "term") %>%
  pivot_wider(values_from = c("estimate", "std.error"), names_from = term) %>%
  write.csv(.,"Samband/StdEstimates.csv") 
  #formattable(.,
  #  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"')

#quantile regression

```


#### Plots
```{r}
aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_intercept, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )

aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(color = respondent)) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting)) +
  scale_y_continuous(limits = c(-4,4)) +
  scale_x_continuous(limits = c(-4,4)) +

  aEstimates %>%
  filter(!respondent == "Alla") %>%
  ggplot(aes(x = respondent, y = estimate_parenting, color = respondent)) +
  geom_point(size = 4, alpha = 0.7) +
  geom_abline(data = aEstimates %>% filter(respondent == "Alla"),
              aes(intercept = mean(estimate_intercept), slope = mean(estimate_parenting)),
              alpha = 0.86, color = "blue", linetype = 2, linewidth = 2) +
  geom_abline(aes(intercept = estimate_intercept, slope = estimate_parenting),
              alpha = 0.2) +
  scale_y_continuous(limits = c(-2, 2)) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
```

#### Plot 2
```{r}

library(ggside)
corSidePlot <- function(data, x, y, smooth = "lm", color) {
  
  data %>%
    ggplot(aes(x = {{ x }}, y = {{ y }}, color = {{ color }})) +
    geom_point2(size = 3, alpha = 0.7) +
    geom_smooth(method = smooth) +
    geom_xsidedensity(aes(y = after_stat(density))) +
    geom_ysidedensity(aes(x = after_stat(density))) +
    geom_xsidehistogram(aes(y = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
    geom_ysidehistogram(aes(x = after_stat(density),
                            fill = {{ color }}), 
                        binwidth = 0.2, alpha = 0.5) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  ) +
  scale_color_manual(
    values = colorRampPalette(colors = c("#009ca6", "#e83c63", "#ffe500"))(4),
    aesthetics = c("fill", "color")
  )
}

df2 %>% 
  corSidePlot(., Utagerande, Parenting)

```

::: panel-tabset
##### 2020
```{r}
df2 %>% 
  filter(ar == 2020) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2018
```{r}
df2 %>% 
  filter(ar == 2018) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2016
```{r}
df2 %>% 
  filter(ar == 2016) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
##### 2014
```{r}
df2 %>% 
  filter(ar == 2014) %>% 
  corSidePlot(., Utagerande, Parenting, color = Kön)
```
:::

### Kvantil regression
```{r}
library(quantreg)
lq1 <- rq(Utagerande ~ Parenting,
  data = df2, tau = 0.5
)
lm1 <- lm(Utagerande ~ Parenting,
  data = df2
)
AIC(lm1, lq1)
tidy(lm1)
tidy(lq1)

ggplot(df2, aes(Utagerande, Parenting)) +
  geom_point(size = 2, alpha = 0.7) +
  geom_smooth(method = "lm", se = T, color = "blue", linewidth = 2) +
  geom_quantile(quantiles = 0.5, color = "red", linewidth = 2) +
  geom_quantile(
    color = "orange", alpha = 0.6,
    quantiles = seq(.1, .9, by = 0.1)
  ) +
  theme_minimal(
    base_family = "Lato",
    base_size = 14
  )
```


### LMM Utagerande 2
```{r}
models2 <- df2 %>%
  split(.$ar) %>%
  map(~ lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .))

compEstimates(models2,5)
sumEstimates(models2)
compRsq(models2)
```

#### Standardiserade effektstorlekar
```{r}
#df2 %>%
#  split(.$ar) %>%
#  map(~ emmeans(lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)), "Parenting")

m2s <- df2 %>% 
  filter(ar == 2016) %>% 
  lm(Utagerande ~ Parenting + SkolaNegativ + Community + Kön, data = .)

emmeans(m2s, "Parenting")
#eff_size(m2emm, edf = 6041, sigma=sigma(m2s))
# borde gå att skriva en funktion för emmeans som går igenom varje år
```


### Utagerande och kriminalitet

#### Antal brott
```{r}
items.brott <- df %>% 
  select(starts_with("f75")) %>% 
  names()

df2 <- df2 %>% 
  mutate(AntalBrott = rowSums(across(all_of(items.brott)), na.rm = T))

df2 %>% 
  ggplot(aes(x = AntalBrott)) +
  geom_bar(fill = RISEprimGreen)
```

#### Test av olika modeller

##### Vanlig poisson regression
```{r}
brott.poi <- glm(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020),
            family = poisson)
summary(brott.poi)
```

##### Negative binomial
```{r}
library(MASS)
brott.nb <- glm.nb(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott.nb)
```


##### Zero-inflated poisson
```{r}
brott.zi <- pscl::zeroinfl(AntalBrott ~ Utagerande + Kön, 
            data = df2 %>% filter(ar == 2020))
summary(brott.zi)
```

##### Hurdle negative binomial
```{r}
brott.hrd <- pscl::hurdle(AntalBrott ~ Utagerande + Kön,
                 dist="negbin", 
                 data = df2 %>% filter(ar == 2020))
summary(brott.hrd)
```

##### AIC jämförelse
```{r}
AIC(brott.poi,brott.nb,brott.zi,brott.hrd) %>% 
  arrange(AIC)
```
Hurdle model har lägst AIC, följd av negative binomial.

#### Visualisering hurdle model
```{r}
predicted <- estimate_expectation(brott2, data = "grid")
plot(predicted) + 
  scale_color_manual(values = RISEpalette1[c(1,5)]) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Hurdle negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
# library(ggeffects)
# pred <- ggpredict(brott2, terms = c("Utagerande","Kön"))
# ggplot(pred, aes(x = x, y = predicted, colour = group)) +
#   geom_line(linewidth = 1.5) +
#   geom_point2() +
#   scale_color_manual(values = RISEpalette1[c(1,5)]) +
#   xlab("Antal självrapporterade brott") +
#   ylab("Indexvärde utagerande")
```

#### Visualisering negative binomial
```{r}
predicted.nb <- estimate_expectation(brott.nb, data = "grid")
plot(predicted.nb) + 
  scale_color_manual(values = RISEpalette1[c(1,5)], aesthetics = c("color","fill")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Negative binomial prediction model") +
  scale_y_continuous(limits = c(0,21), breaks = c(0,3,6,9,12,15,18,21))
```


#### Dikotomiserat utfall
Vi kodar en variabel där antal brott 0-2 = 0, och 3 eller fler blir 1.
```{r}
df <- df %>% 
  mutate(BrottDik = car::recode(AntalBrott,"0:2=0;3:19=1", as.factor = FALSE))

brott.dik <- glm(BrottDik ~ Utagerande + Parenting, 
            data = df %>% filter(Kön == "Pojke"),
            family = binomial)
modelsummary(brott.dik)
```

```{r}
plot(parameters(brott.dik))

predicted <- estimate_expectation(brott.poi.dik, data = "grid")
plot(predicted) +
  scale_color_manual(values = RISEpalette1[c(1,5)], 
                     aesthetics = c("fill","color")) +
  ylab("Antal självrapporterade brott") +
  xlab("Indexvärde utagerande") +
  labs(title = "Logistic regression prediction model")

### only for linear models:
# check <- check_normality(brott0)
# plot(check, type = "qq")
```

```{r}
# augment(brott.poi.dik) %>% 
#   filter(BrottDik == 1) %>% 
#   select(Utagerande) %>% 
#   summary()

augment(brott.poi.dik) %>%
  ggplot(aes(x = Utagerande, fill = BrottDik, group = BrottDik)) +
  geom_density(alpha = 0.7) +
  geom_vline(aes(xintercept = 0.9), color = "red", linetype = 2) +
  theme_bw() +
  scale_fill_viridis_c()
  
```

### Machine Learning modeling

#### Logistic penalized regression

```{r}
library(tidymodels)
library(dotwhisker)
library(vip)         # for variable importance plots
library(ranger)
df2$BrottDik2 <- factor(df2$BrottDik, levels = c(0,1),
                        labels = c("Låg","Hög"))

ml_vars <- c("BrottDik2","Utagerande","Kön","Parenting","Community","SkolaNegativ")

df3 <- df2 %>% 
  dplyr::select(any_of(ml_vars),ar) %>% 
  na.omit()

splits <- initial_validation_split(df3, strata = ar)
df_train <- training(splits)
df_test  <- testing(splits)
val_set <- initial_validation_split(df_train, 
                            strata = ar, 
                            #prop = c(0.8,0.2)
                            )
df_fold <- vfold_cv(df_train, v = 10)
```

```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")


lr_fit <- 
  lr_mod %>% 
  fit(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)

lr_recipe <- 
  recipe(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())# %>% 
  #step_normalize(all_numeric_predictors())

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
#| eval: true
#lr_splits <- vfold_cv(df_other, v = 10, strata = ar)
#_res <- tune_grid(lr_mod, ames_rec, resamples = cv_splits, grid = spline_grid)

#lr_reg_grid <- tibble(penalty = 10^seq(-5, -1, length.out = 40))
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)

lr_res <- 
  tune_grid(lr_workflow,
            resamples = df_fold,
            grid = penalty_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# lr_res <-
#   lr_workflow %>%
#   tune_grid(val_set,
#             grid = penalty_grid,
#             control = control_grid(save_pred = TRUE),
#             metrics = metric_set(roc_auc))

lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC") +
  scale_x_log10(labels = scales::label_number())

top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 
top_models

lr_best <- lr_res %>% 
  select_best()

lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(BrottDik2, `.pred_Hög`) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```


```{r}
#| eval: true

last_lr_mod <- 
  logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")

last_lr_workflow <- 
  lr_workflow %>% 
  update_model(last_lr_mod)

last_lr_fit <- 
  last_lr_workflow %>% 
  last_fit(splits)

last_lr_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

## Psy

```{r}
ml_vars2 <- c("PsykSomBesv","Utagerande","Kön","Parenting","Community","SkolaNegativ")

df.ml <- df2 %>% 
  dplyr::select(any_of(ml_vars2),ar) %>% 
  na.omit()

splits <- initial_split(df.ml, strata = ar)
df_train <- training(splits)
df_test  <- testing(splits)
val_set <- validation_split(df_train, 
                            strata = ar, 
                            prop = 0.80)
df_fold <- vfold_cv(df_train, v = 10)
```

```{r}
lm_mod <- 
  linear_reg() %>% 
  set_engine("lm")

lm_fit <- 
  lm_mod %>% 
  fit(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ + ar, data = df_train)

# lm_fit %>% 
#   extract_fit_engine() %>% 
#   plot()

tidy(lm_fit) %>% 
  dwplot(dot_args = list(size = 2, color = "black"),
         whisker_args = list(color = "black"),
         vline = geom_vline(xintercept = 0, colour = "grey50", linetype = 2))

lm_fit %>% 
  extract_fit_engine() %>% 
  vip(num_features = 20)
```

```{r}
ref_data <- df2 %>% 
  group_by(ar,Kön) %>% 
  summarise(Utagerande = mean(Utagerande, na.rm = T),
            Parenting = mean(Parenting, na.rm = T),
            Community = mean(Community, na.rm = T),
            SkolaNegativ = mean(SkolaNegativ, na.rm = T)) %>% 
  ungroup()

# add set of rows for 2024
ref_data <- rbind(ref_data,ref_data[(nrow(ref_data)-1):nrow(ref_data),]) %>% tail()
#ref_data$ar <- rep(c(årtal,2022,2024), each = 2)

mean_pred <- predict(lm_fit, new_data = ref_data)
conf_int_pred <- predict(lm_fit, 
                         new_data = ref_data, 
                         type = "conf_int")


plot_data <- 
  ref_data %>% 
  bind_cols(mean_pred) %>% 
  bind_cols(conf_int_pred)

ggplot(plot_data, aes(x = ar, color = Kön)) + 
  geom_point(aes(y = .pred)) + 
  geom_errorbar(aes(ymin = .pred_lower, 
                    ymax = .pred_upper),
                width = .2) + 
  labs(y = "psy besv")

#new_data <- ref_data %>% 
#  select(ar,)
```


```{r}
lm_recipe <- 
  recipe(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())

lm_workflow <- 
  workflow() %>% 
  add_model(lm_mod) %>% 
  add_recipe(lm_recipe)


```


```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")

# https://www.tmwr.org/workflow-sets
#library(rules)
#library(baguette)
linear_reg_spec <- 
   linear_reg(penalty = tune(), mixture = tune()) %>% 
   set_engine("glmnet")

nnet_spec <- 
   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
   set_engine("nnet", MaxNWts = 2600) %>% 
   set_mode("regression")

cart_spec <- 
   decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
   set_engine("rpart") %>% 
   set_mode("regression")

bag_cart_spec <- 
   bag_tree() %>% 
   set_engine("rpart", times = 50L) %>% 
   set_mode("regression")

xgb_spec <- 
   boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), 
              min_n = tune(), sample_size = tune(), trees = tune()) %>% 
   set_engine("xgboost") %>% 
   set_mode("regression")

nnet_param <- 
   nnet_spec %>% 
   extract_parameter_set_dials() %>% 
   update(hidden_units = hidden_units(c(1, 27)))

```

```{r}
nnet_fit <-
  nnet_spec %>% 
  fit(PsykSomBesv ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)
```


```{r}
lr_fit <- 
  lr_mod %>% 
  fit(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train)

lr_recipe <- 
  recipe(BrottDik2 ~ Utagerande + Kön + Parenting + Community + SkolaNegativ, data = df_train) %>%
  step_novel(all_nominal_predictors()) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_zv(all_predictors())# %>% 
  #step_normalize(all_numeric_predictors())

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```

```{r}
#| eval: true
#lr_splits <- vfold_cv(df_other, v = 10, strata = ar)
#_res <- tune_grid(lr_mod, ames_rec, resamples = cv_splits, grid = spline_grid)

#lr_reg_grid <- tibble(penalty = 10^seq(-5, -1, length.out = 40))
penalty_grid <- grid_regular(penalty(range = c(-5, 5)), levels = 50)

lr_res <- 
  tune_grid(lr_workflow,
            resamples = df_fold,
            grid = penalty_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))

# lr_res <-
#   lr_workflow %>%
#   tune_grid(val_set,
#             grid = penalty_grid,
#             control = control_grid(save_pred = TRUE),
#             metrics = metric_set(roc_auc))

lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 5) %>% 
  arrange(penalty) 
top_models

lr_best <- lr_res %>% 
  select_best()

lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>% 
  roc_curve(BrottDik2, `.pred_Hög`) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)
```


```{r}
#| eval: true

last_lr_mod <- 
  logistic_reg(penalty = lr_best$penalty, mixture = 1) %>% 
  set_engine("glmnet")

last_lr_workflow <- 
  lr_workflow %>% 
  update_model(last_lr_mod)

last_lr_fit <- 
  last_lr_workflow %>% 
  last_fit(splits)

last_lr_fit %>% 
  extract_fit_parsnip() %>% 
  vip(num_features = 20)
```

## Programvara som använts

```{r}
#| label: packagesv
pkgs <- cite_packages(
  cite.tidyverse = TRUE,
  output = "table",
  bib.file = "grateful-refs.bib",
  include.RStudio = TRUE,
  out.dir = getwd()
)
formattable(pkgs,
  table.attr = 'class=\"table table-striped\" style="font-size: 14px; font-family: Lato; width: 80%"'
)
```

## Referenser
